tensor(17.6623)
tensor(66.5108)
[TRAIN] Epoch 1/20, Batch 1/34, Loss: 84.17308044433594, Acc: 0.0
tensor(56.0972)
tensor(98.6058)
[TRAIN] Epoch 1/20, Batch 2/34, Loss: 119.43803405761719, Acc: 0.0
tensor(16.4884)
tensor(47.3627)
[TRAIN] Epoch 1/20, Batch 3/34, Loss: 100.9090576171875, Acc: 0.0
tensor(24.1335)
tensor(25.3143)
[TRAIN] Epoch 1/20, Batch 4/34, Loss: 88.04374694824219, Acc: 0.0
tensor(22.2463)
tensor(59.3418)
[TRAIN] Epoch 1/20, Batch 5/34, Loss: 86.75260925292969, Acc: 0.0
tensor(7.3006)
tensor(64.4876)
[TRAIN] Epoch 1/20, Batch 6/34, Loss: 84.258544921875, Acc: 0.0
tensor(4.7917)
tensor(59.5712)
[TRAIN] Epoch 1/20, Batch 7/34, Loss: 81.41631317138672, Acc: 0.0
tensor(13.5269)
tensor(36.1123)
[TRAIN] Epoch 1/20, Batch 8/34, Loss: 77.44418334960938, Acc: 0.0
tensor(24.2606)
tensor(25.9076)
[TRAIN] Epoch 1/20, Batch 9/34, Loss: 74.41351318359375, Acc: 0.0
tensor(6.5555)
tensor(53.0966)
[TRAIN] Epoch 1/20, Batch 10/34, Loss: 72.93737030029297, Acc: 0.0
tensor(11.1152)
tensor(44.1846)
[TRAIN] Epoch 1/20, Batch 11/34, Loss: 71.3339614868164, Acc: 0.0
tensor(26.9419)
tensor(51.9645)
[TRAIN] Epoch 1/20, Batch 12/34, Loss: 71.96499633789062, Acc: 0.0
tensor(10.9024)
tensor(35.3054)
[TRAIN] Epoch 1/20, Batch 13/34, Loss: 69.98368072509766, Acc: 0.0
tensor(9.3890)
tensor(43.1249)
[TRAIN] Epoch 1/20, Batch 14/34, Loss: 68.73583984375, Acc: 0.0
tensor(8.9400)
tensor(42.2070)
[TRAIN] Epoch 1/20, Batch 15/34, Loss: 67.56324768066406, Acc: 0.0
tensor(11.7652)
tensor(27.5548)
[TRAIN] Epoch 1/20, Batch 16/34, Loss: 65.79804229736328, Acc: 0.0
tensor(14.9919)
tensor(53.7822)
[TRAIN] Epoch 1/20, Batch 17/34, Loss: 65.97309875488281, Acc: 0.0
tensor(9.2914)
tensor(41.7437)
[TRAIN] Epoch 1/20, Batch 18/34, Loss: 65.14321899414062, Acc: 0.0
tensor(5.5499)
tensor(53.1859)
[TRAIN] Epoch 1/20, Batch 19/34, Loss: 64.80597686767578, Acc: 0.0
tensor(3.3078)
tensor(52.3828)
[TRAIN] Epoch 1/20, Batch 20/34, Loss: 64.35021209716797, Acc: 0.0
tensor(5.0396)
tensor(54.3588)
[TRAIN] Epoch 1/20, Batch 21/34, Loss: 64.11441802978516, Acc: 0.0
tensor(8.3501)
tensor(38.7539)
[TRAIN] Epoch 1/20, Batch 22/34, Loss: 63.34121322631836, Acc: 0.0
tensor(17.7148)
tensor(34.2642)
[TRAIN] Epoch 1/20, Batch 23/34, Loss: 62.847206115722656, Acc: 0.002717391304347826
tensor(16.7147)
tensor(31.8612)
[TRAIN] Epoch 1/20, Batch 24/34, Loss: 62.252567291259766, Acc: 0.005208333333333333
tensor(15.0447)
tensor(32.8747)
[TRAIN] Epoch 1/20, Batch 25/34, Loss: 61.679237365722656, Acc: 0.005
tensor(6.4690)
tensor(39.4203)
[TRAIN] Epoch 1/20, Batch 26/34, Loss: 61.07193374633789, Acc: 0.004807692307692308
tensor(4.8256)
tensor(49.4683)
[TRAIN] Epoch 1/20, Batch 27/34, Loss: 60.820892333984375, Acc: 0.004629629629629629
tensor(5.2761)
tensor(52.5562)
[TRAIN] Epoch 1/20, Batch 28/34, Loss: 60.71415328979492, Acc: 0.004464285714285714
tensor(6.7677)
tensor(36.4975)
[TRAIN] Epoch 1/20, Batch 29/34, Loss: 60.11246871948242, Acc: 0.004310344827586207
tensor(7.2439)
tensor(32.1204)
[TRAIN] Epoch 1/20, Batch 30/34, Loss: 59.420860290527344, Acc: 0.004166666666666667
tensor(7.5324)
tensor(25.3739)
[TRAIN] Epoch 1/20, Batch 31/34, Loss: 58.5655517578125, Acc: 0.004032258064516129
tensor(11.8361)
tensor(28.3319)
[TRAIN] Epoch 1/20, Batch 32/34, Loss: 57.99062728881836, Acc: 0.00390625
tensor(13.0752)
tensor(38.7895)
[TRAIN] Epoch 1/20, Batch 33/34, Loss: 57.80499267578125, Acc: 0.003787878787878788
tensor(9.5922)
tensor(14.0924)
[TRAIN] Epoch 1/20, Batch 34/34, Loss: 56.23545837402344, Acc: 0.003676470588235294
tensor(7.6527)
tensor(25.1955)
[TRAIN] Epoch 2/20, Batch 1/34, Loss: 32.848243713378906, Acc: 0.25
tensor(9.4408)
tensor(23.4631)
[TRAIN] Epoch 2/20, Batch 2/34, Loss: 32.87604904174805, Acc: 0.125
tensor(8.1958)
tensor(29.8755)
[TRAIN] Epoch 2/20, Batch 3/34, Loss: 34.6077995300293, Acc: 0.08333333333333333
tensor(7.4049)
tensor(26.4374)
[TRAIN] Epoch 2/20, Batch 4/34, Loss: 34.416412353515625, Acc: 0.0625
tensor(6.3736)
tensor(30.8614)
[TRAIN] Epoch 2/20, Batch 5/34, Loss: 34.980125427246094, Acc: 0.05
tensor(6.7694)
tensor(27.7226)
[TRAIN] Epoch 2/20, Batch 6/34, Loss: 34.89876174926758, Acc: 0.041666666666666664
tensor(5.7152)
tensor(24.5194)
[TRAIN] Epoch 2/20, Batch 7/34, Loss: 34.23245620727539, Acc: 0.03571428571428571
tensor(6.1748)
tensor(25.5376)
[TRAIN] Epoch 2/20, Batch 8/34, Loss: 33.917449951171875, Acc: 0.03125
tensor(4.4301)
tensor(18.7150)
[TRAIN] Epoch 2/20, Batch 9/34, Loss: 32.72052764892578, Acc: 0.027777777777777776
tensor(6.5464)
tensor(19.1826)
[TRAIN] Epoch 2/20, Batch 10/34, Loss: 32.02137756347656, Acc: 0.0375
tensor(6.1072)
tensor(27.8521)
[TRAIN] Epoch 2/20, Batch 11/34, Loss: 32.19755172729492, Acc: 0.03409090909090909
tensor(4.0341)
tensor(20.7547)
[TRAIN] Epoch 2/20, Batch 12/34, Loss: 31.580154418945312, Acc: 0.03125
tensor(4.8660)
tensor(19.9792)
[TRAIN] Epoch 2/20, Batch 13/34, Loss: 31.06208038330078, Acc: 0.03365384615384615
tensor(6.5905)
tensor(22.0305)
[TRAIN] Epoch 2/20, Batch 14/34, Loss: 30.88771629333496, Acc: 0.03571428571428571
tensor(5.3259)
tensor(21.7662)
[TRAIN] Epoch 2/20, Batch 15/34, Loss: 30.634675979614258, Acc: 0.03333333333333333
tensor(5.7354)
tensor(19.4553)
[TRAIN] Epoch 2/20, Batch 16/34, Loss: 30.294422149658203, Acc: 0.03515625
tensor(5.9042)
tensor(17.8059)
[TRAIN] Epoch 2/20, Batch 17/34, Loss: 29.907106399536133, Acc: 0.03676470588235294
tensor(5.3800)
tensor(28.9543)
[TRAIN] Epoch 2/20, Batch 18/34, Loss: 30.153066635131836, Acc: 0.041666666666666664
tensor(5.6567)
tensor(26.0194)
[TRAIN] Epoch 2/20, Batch 19/34, Loss: 30.23322868347168, Acc: 0.039473684210526314
tensor(7.0867)
tensor(24.5790)
[TRAIN] Epoch 2/20, Batch 20/34, Loss: 30.304851531982422, Acc: 0.040625
tensor(5.6986)
tensor(21.3317)
[TRAIN] Epoch 2/20, Batch 21/34, Loss: 30.1489200592041, Acc: 0.03869047619047619
tensor(4.8200)
tensor(21.1317)
[TRAIN] Epoch 2/20, Batch 22/34, Loss: 29.95813751220703, Acc: 0.03977272727272727
tensor(6.2037)
tensor(17.6526)
[TRAIN] Epoch 2/20, Batch 23/34, Loss: 29.692842483520508, Acc: 0.04619565217391304
tensor(5.5256)
tensor(16.5625)
[TRAIN] Epoch 2/20, Batch 24/34, Loss: 29.3759765625, Acc: 0.044270833333333336
tensor(4.5479)
tensor(18.8600)
[TRAIN] Epoch 2/20, Batch 25/34, Loss: 29.137252807617188, Acc: 0.0475
tensor(4.6687)
tensor(23.4226)
[TRAIN] Epoch 2/20, Batch 26/34, Loss: 29.097023010253906, Acc: 0.04567307692307692
tensor(4.3435)
tensor(21.8962)
[TRAIN] Epoch 2/20, Batch 27/34, Loss: 28.99119758605957, Acc: 0.046296296296296294
tensor(3.8386)
tensor(20.8967)
[TRAIN] Epoch 2/20, Batch 28/34, Loss: 28.839202880859375, Acc: 0.044642857142857144
tensor(5.8619)
tensor(21.8223)
[TRAIN] Epoch 2/20, Batch 29/34, Loss: 28.799375534057617, Acc: 0.04741379310344827
tensor(4.3688)
tensor(20.7174)
[TRAIN] Epoch 2/20, Batch 30/34, Loss: 28.675600051879883, Acc: 0.04791666666666667
tensor(4.0250)
tensor(22.5069)
[TRAIN] Epoch 2/20, Batch 31/34, Loss: 28.606449127197266, Acc: 0.04838709677419355
tensor(3.9763)
tensor(25.9162)
[TRAIN] Epoch 2/20, Batch 32/34, Loss: 28.646638870239258, Acc: 0.046875
tensor(4.4321)
tensor(20.4004)
[TRAIN] Epoch 2/20, Batch 33/34, Loss: 28.53106117248535, Acc: 0.045454545454545456
tensor(3.8871)
tensor(22.5412)
[TRAIN] Epoch 2/20, Batch 34/34, Loss: 27.837657928466797, Acc: 0.04411764705882353
tensor(4.3503)
tensor(18.0540)
[TRAIN] Epoch 3/20, Batch 1/34, Loss: 22.404279708862305, Acc: 0.125
tensor(4.9643)
tensor(20.5453)
[TRAIN] Epoch 3/20, Batch 2/34, Loss: 23.956928253173828, Acc: 0.09375
tensor(4.4110)
tensor(23.0613)
[TRAIN] Epoch 3/20, Batch 3/34, Loss: 25.12870979309082, Acc: 0.08333333333333333
tensor(4.1877)
tensor(19.0324)
[TRAIN] Epoch 3/20, Batch 4/34, Loss: 24.651569366455078, Acc: 0.078125
tensor(3.6912)
tensor(21.9948)
[TRAIN] Epoch 3/20, Batch 5/34, Loss: 24.858463287353516, Acc: 0.075
tensor(4.8767)
tensor(18.8328)
[TRAIN] Epoch 3/20, Batch 6/34, Loss: 24.666975021362305, Acc: 0.0625
tensor(4.1115)
tensor(20.9035)
[TRAIN] Epoch 3/20, Batch 7/34, Loss: 24.716693878173828, Acc: 0.05357142857142857
tensor(3.5127)
tensor(24.2070)
[TRAIN] Epoch 3/20, Batch 8/34, Loss: 25.092063903808594, Acc: 0.046875
tensor(3.3954)
tensor(21.4007)
[TRAIN] Epoch 3/20, Batch 9/34, Loss: 25.059181213378906, Acc: 0.04861111111111111
tensor(4.1118)
tensor(18.9922)
[TRAIN] Epoch 3/20, Batch 10/34, Loss: 24.863666534423828, Acc: 0.06875
tensor(5.0682)
tensor(19.5216)
[TRAIN] Epoch 3/20, Batch 11/34, Loss: 24.838768005371094, Acc: 0.06818181818181818
tensor(5.0837)
tensor(15.9811)
[TRAIN] Epoch 3/20, Batch 12/34, Loss: 24.524267196655273, Acc: 0.06770833333333333
tensor(4.7505)
tensor(20.1575)
[TRAIN] Epoch 3/20, Batch 13/34, Loss: 24.553791046142578, Acc: 0.0625
tensor(3.7860)
tensor(24.0903)
[TRAIN] Epoch 3/20, Batch 14/34, Loss: 24.791107177734375, Acc: 0.0625
tensor(3.1614)
tensor(21.7896)
[TRAIN] Epoch 3/20, Batch 15/34, Loss: 24.8017635345459, Acc: 0.0625
tensor(3.3192)
tensor(21.5332)
[TRAIN] Epoch 3/20, Batch 16/34, Loss: 24.8049259185791, Acc: 0.05859375
tensor(3.9663)
tensor(16.0820)
[TRAIN] Epoch 3/20, Batch 17/34, Loss: 24.525127410888672, Acc: 0.058823529411764705
tensor(4.6115)
tensor(16.9438)
[TRAIN] Epoch 3/20, Batch 18/34, Loss: 24.36014175415039, Acc: 0.059027777777777776
tensor(3.7449)
tensor(13.8830)
[TRAIN] Epoch 3/20, Batch 19/34, Loss: 24.005809783935547, Acc: 0.0625
tensor(4.8202)
tensor(16.7976)
[TRAIN] Epoch 3/20, Batch 20/34, Loss: 23.886409759521484, Acc: 0.06875
tensor(3.7712)
tensor(15.6100)
[TRAIN] Epoch 3/20, Batch 21/34, Loss: 23.671875, Acc: 0.06547619047619048
tensor(3.9613)
tensor(24.7625)
[TRAIN] Epoch 3/20, Batch 22/34, Loss: 23.901508331298828, Acc: 0.06818181818181818
tensor(4.6080)
tensor(19.8028)
[TRAIN] Epoch 3/20, Batch 23/34, Loss: 23.92365074157715, Acc: 0.06793478260869565
tensor(4.4077)
tensor(15.1975)
[TRAIN] Epoch 3/20, Batch 24/34, Loss: 23.74371337890625, Acc: 0.06770833333333333
tensor(4.1734)
tensor(23.0815)
[TRAIN] Epoch 3/20, Batch 25/34, Loss: 23.8841609954834, Acc: 0.065
tensor(4.2427)
tensor(18.9131)
[TRAIN] Epoch 3/20, Batch 26/34, Loss: 23.856143951416016, Acc: 0.0673076923076923
tensor(3.1541)
tensor(19.3447)
[TRAIN] Epoch 3/20, Batch 27/34, Loss: 23.805870056152344, Acc: 0.06944444444444445
tensor(3.3689)
tensor(22.1977)
[TRAIN] Epoch 3/20, Batch 28/34, Loss: 23.868749618530273, Acc: 0.07142857142857142
tensor(4.3818)
tensor(20.3331)
[TRAIN] Epoch 3/20, Batch 29/34, Loss: 23.89792823791504, Acc: 0.06896551724137931
tensor(3.9211)
tensor(18.1293)
[TRAIN] Epoch 3/20, Batch 30/34, Loss: 23.836341857910156, Acc: 0.07083333333333333
tensor(4.5014)
tensor(17.1545)
[TRAIN] Epoch 3/20, Batch 31/34, Loss: 23.76600456237793, Acc: 0.07056451612903226
tensor(3.1011)
tensor(17.3353)
[TRAIN] Epoch 3/20, Batch 32/34, Loss: 23.661956787109375, Acc: 0.0703125
tensor(4.0130)
tensor(14.6975)
[TRAIN] Epoch 3/20, Batch 33/34, Loss: 23.511913299560547, Acc: 0.07196969696969698
tensor(2.2132)
tensor(13.4226)
[TRAIN] Epoch 3/20, Batch 34/34, Loss: 22.906612396240234, Acc: 0.06985294117647059
tensor(3.8156)
tensor(17.0187)
[TRAIN] Epoch 4/20, Batch 1/34, Loss: 20.834300994873047, Acc: 0.125
tensor(3.1927)
tensor(24.3360)
[TRAIN] Epoch 4/20, Batch 2/34, Loss: 24.181535720825195, Acc: 0.125
tensor(3.9675)
tensor(25.1923)
[TRAIN] Epoch 4/20, Batch 3/34, Loss: 25.840978622436523, Acc: 0.08333333333333333
tensor(4.2543)
tensor(23.0854)
[TRAIN] Epoch 4/20, Batch 4/34, Loss: 26.215667724609375, Acc: 0.078125
tensor(5.4948)
tensor(21.2755)
[TRAIN] Epoch 4/20, Batch 5/34, Loss: 26.326583862304688, Acc: 0.0625
tensor(4.2434)
tensor(19.9858)
[TRAIN] Epoch 4/20, Batch 6/34, Loss: 25.977027893066406, Acc: 0.052083333333333336
tensor(4.1033)
tensor(16.3219)
[TRAIN] Epoch 4/20, Batch 7/34, Loss: 25.18389892578125, Acc: 0.08035714285714286
tensor(3.8413)
tensor(18.6258)
[TRAIN] Epoch 4/20, Batch 8/34, Loss: 24.844297409057617, Acc: 0.0859375
tensor(2.9914)
tensor(22.4733)
[TRAIN] Epoch 4/20, Batch 9/34, Loss: 24.913225173950195, Acc: 0.0763888888888889
tensor(3.6229)
tensor(20.7393)
[TRAIN] Epoch 4/20, Batch 10/34, Loss: 24.858123779296875, Acc: 0.08125
tensor(3.7290)
tensor(17.9838)
[TRAIN] Epoch 4/20, Batch 11/34, Loss: 24.572181701660156, Acc: 0.07386363636363637
tensor(4.0348)
tensor(15.7140)
[TRAIN] Epoch 4/20, Batch 12/34, Loss: 24.17024040222168, Acc: 0.07291666666666667
tensor(4.5361)
tensor(17.0584)
[TRAIN] Epoch 4/20, Batch 13/34, Loss: 23.972105026245117, Acc: 0.07692307692307693
tensor(4.4718)
tensor(17.5390)
[TRAIN] Epoch 4/20, Batch 14/34, Loss: 23.83201026916504, Acc: 0.08035714285714286
tensor(3.7051)
tensor(17.9158)
[TRAIN] Epoch 4/20, Batch 15/34, Loss: 23.684598922729492, Acc: 0.07916666666666666
tensor(3.5878)
tensor(17.7805)
[TRAIN] Epoch 4/20, Batch 16/34, Loss: 23.539827346801758, Acc: 0.078125
tensor(4.0076)
tensor(19.1760)
[TRAIN] Epoch 4/20, Batch 17/34, Loss: 23.518869400024414, Acc: 0.08088235294117647
tensor(4.0585)
tensor(17.5325)
[TRAIN] Epoch 4/20, Batch 18/34, Loss: 23.41176414489746, Acc: 0.08333333333333333
tensor(3.4482)
tensor(23.9308)
[TRAIN] Epoch 4/20, Batch 19/34, Loss: 23.62056541442871, Acc: 0.07894736842105263
tensor(4.0130)
tensor(22.8415)
[TRAIN] Epoch 4/20, Batch 20/34, Loss: 23.78226661682129, Acc: 0.075
tensor(3.9627)
tensor(15.3235)
[TRAIN] Epoch 4/20, Batch 21/34, Loss: 23.56817054748535, Acc: 0.07738095238095238
tensor(4.1626)
tensor(14.7294)
[TRAIN] Epoch 4/20, Batch 22/34, Loss: 23.355615615844727, Acc: 0.07954545454545454
tensor(3.9909)
tensor(23.0009)
[TRAIN] Epoch 4/20, Batch 23/34, Loss: 23.513708114624023, Acc: 0.07880434782608696
tensor(4.5615)
tensor(18.5482)
[TRAIN] Epoch 4/20, Batch 24/34, Loss: 23.496877670288086, Acc: 0.078125
tensor(3.3501)
tensor(20.1073)
[TRAIN] Epoch 4/20, Batch 25/34, Loss: 23.495298385620117, Acc: 0.0825
tensor(3.5887)
tensor(24.6987)
[TRAIN] Epoch 4/20, Batch 26/34, Loss: 23.679609298706055, Acc: 0.08173076923076923
tensor(3.0941)
tensor(17.3170)
[TRAIN] Epoch 4/20, Batch 27/34, Loss: 23.55855369567871, Acc: 0.0787037037037037
tensor(3.9666)
tensor(17.7612)
[TRAIN] Epoch 4/20, Batch 28/34, Loss: 23.493167877197266, Acc: 0.078125
tensor(4.0424)
tensor(15.5630)
[TRAIN] Epoch 4/20, Batch 29/34, Loss: 23.35910987854004, Acc: 0.07974137931034483
tensor(4.7605)
tensor(18.4492)
[TRAIN] Epoch 4/20, Batch 30/34, Loss: 23.354127883911133, Acc: 0.08125
tensor(4.8837)
tensor(21.3329)
[TRAIN] Epoch 4/20, Batch 31/34, Loss: 23.44646644592285, Acc: 0.08064516129032258
tensor(3.8645)
tensor(17.0906)
[TRAIN] Epoch 4/20, Batch 32/34, Loss: 23.36861228942871, Acc: 0.080078125
tensor(3.9146)
tensor(15.9408)
[TRAIN] Epoch 4/20, Batch 33/34, Loss: 23.262149810791016, Acc: 0.07954545454545454
tensor(2.1584)
tensor(7.8538)
[TRAIN] Epoch 4/20, Batch 34/34, Loss: 22.633182525634766, Acc: 0.07720588235294118
tensor(3.6336)
tensor(19.2911)
[TRAIN] Epoch 5/20, Batch 1/34, Loss: 22.924686431884766, Acc: 0.125
tensor(4.2308)
tensor(19.6201)
[TRAIN] Epoch 5/20, Batch 2/34, Loss: 23.38780975341797, Acc: 0.09375
tensor(5.1626)
tensor(19.4647)
[TRAIN] Epoch 5/20, Batch 3/34, Loss: 23.80097007751465, Acc: 0.10416666666666667
tensor(3.8590)
tensor(18.9507)
[TRAIN] Epoch 5/20, Batch 4/34, Loss: 23.55315589904785, Acc: 0.109375
tensor(4.0993)
tensor(17.3026)
[TRAIN] Epoch 5/20, Batch 5/34, Loss: 23.122909545898438, Acc: 0.1
tensor(3.8853)
tensor(20.2800)
[TRAIN] Epoch 5/20, Batch 6/34, Loss: 23.296655654907227, Acc: 0.08333333333333333
tensor(4.2403)
tensor(18.1118)
[TRAIN] Epoch 5/20, Batch 7/34, Loss: 23.16171646118164, Acc: 0.08035714285714286
tensor(3.5432)
tensor(18.5504)
[TRAIN] Epoch 5/20, Batch 8/34, Loss: 23.028207778930664, Acc: 0.0859375
tensor(3.7131)
tensor(18.1859)
[TRAIN] Epoch 5/20, Batch 9/34, Loss: 22.902740478515625, Acc: 0.08333333333333333
tensor(4.1711)
tensor(18.9701)
[TRAIN] Epoch 5/20, Batch 10/34, Loss: 22.926593780517578, Acc: 0.08125
tensor(3.5298)
tensor(15.8598)
[TRAIN] Epoch 5/20, Batch 11/34, Loss: 22.605052947998047, Acc: 0.08522727272727272
tensor(3.4970)
tensor(18.3485)
[TRAIN] Epoch 5/20, Batch 12/34, Loss: 22.54175567626953, Acc: 0.08333333333333333
tensor(3.6475)
tensor(18.9093)
[TRAIN] Epoch 5/20, Batch 13/34, Loss: 22.542919158935547, Acc: 0.08173076923076923
tensor(3.7259)
tensor(17.7588)
[TRAIN] Epoch 5/20, Batch 14/34, Loss: 22.467330932617188, Acc: 0.08035714285714286
tensor(3.9376)
tensor(21.5120)
[TRAIN] Epoch 5/20, Batch 15/34, Loss: 22.66615104675293, Acc: 0.07916666666666666
tensor(3.4976)
tensor(16.7835)
[TRAIN] Epoch 5/20, Batch 16/34, Loss: 22.51708221435547, Acc: 0.078125
tensor(3.2820)
tensor(13.6143)
[TRAIN] Epoch 5/20, Batch 17/34, Loss: 22.186447143554688, Acc: 0.07352941176470588
tensor(3.2671)
tensor(14.7742)
[TRAIN] Epoch 5/20, Batch 18/34, Loss: 21.95616340637207, Acc: 0.0763888888888889
tensor(2.7183)
tensor(16.4976)
[TRAIN] Epoch 5/20, Batch 19/34, Loss: 21.811935424804688, Acc: 0.07894736842105263
tensor(3.5583)
tensor(15.2209)
[TRAIN] Epoch 5/20, Batch 20/34, Loss: 21.660297393798828, Acc: 0.08125
tensor(3.2120)
tensor(20.2527)
[TRAIN] Epoch 5/20, Batch 21/34, Loss: 21.7462215423584, Acc: 0.08035714285714286
tensor(3.3525)
tensor(15.8182)
[TRAIN] Epoch 5/20, Batch 22/34, Loss: 21.629150390625, Acc: 0.07954545454545454
tensor(3.4358)
tensor(14.4851)
[TRAIN] Epoch 5/20, Batch 23/34, Loss: 21.46792221069336, Acc: 0.07880434782608696
tensor(3.4595)
tensor(14.2787)
[TRAIN] Epoch 5/20, Batch 24/34, Loss: 21.312517166137695, Acc: 0.078125
tensor(3.3706)
tensor(17.1348)
[TRAIN] Epoch 5/20, Batch 25/34, Loss: 21.280235290527344, Acc: 0.075
tensor(3.2784)
tensor(16.5963)
[TRAIN] Epoch 5/20, Batch 26/34, Loss: 21.226177215576172, Acc: 0.07451923076923077
tensor(3.3276)
tensor(15.6649)
[TRAIN] Epoch 5/20, Batch 27/34, Loss: 21.143447875976562, Acc: 0.08101851851851852
tensor(3.4818)
tensor(18.7736)
[TRAIN] Epoch 5/20, Batch 28/34, Loss: 21.18316078186035, Acc: 0.08035714285714286
tensor(4.0435)
tensor(14.3762)
[TRAIN] Epoch 5/20, Batch 29/34, Loss: 21.08786964416504, Acc: 0.08189655172413793
tensor(3.9847)
tensor(15.2603)
[TRAIN] Epoch 5/20, Batch 30/34, Loss: 21.026437759399414, Acc: 0.08125
tensor(3.9247)
tensor(16.1332)
[TRAIN] Epoch 5/20, Batch 31/34, Loss: 20.995195388793945, Acc: 0.08064516129032258
tensor(3.7372)
tensor(15.6417)
[TRAIN] Epoch 5/20, Batch 32/34, Loss: 20.944686889648438, Acc: 0.080078125
tensor(3.8044)
tensor(17.9308)
[TRAIN] Epoch 5/20, Batch 33/34, Loss: 20.968643188476562, Acc: 0.07954545454545454
tensor(4.3410)
tensor(17.7684)
[TRAIN] Epoch 5/20, Batch 34/34, Loss: 20.473844528198242, Acc: 0.07904411764705882
[VAL] Acc: 0.22033898305084745
[TEST] Acc: 0.288135593220339
tensor(3.3844)
tensor(16.7177)
[TRAIN] Epoch 6/20, Batch 1/34, Loss: 20.10210418701172, Acc: 0.0
tensor(3.5030)
tensor(19.1912)
[TRAIN] Epoch 6/20, Batch 2/34, Loss: 21.39810562133789, Acc: 0.0625
tensor(3.8662)
tensor(17.4492)
[TRAIN] Epoch 6/20, Batch 3/34, Loss: 21.370519638061523, Acc: 0.14583333333333334
tensor(4.6458)
tensor(18.6752)
[TRAIN] Epoch 6/20, Batch 4/34, Loss: 21.858158111572266, Acc: 0.140625
tensor(3.8666)
tensor(16.8143)
[TRAIN] Epoch 6/20, Batch 5/34, Loss: 21.622718811035156, Acc: 0.15
tensor(4.0167)
tensor(15.5369)
[TRAIN] Epoch 6/20, Batch 6/34, Loss: 21.277870178222656, Acc: 0.13541666666666666
tensor(3.5582)
tensor(14.9661)
[TRAIN] Epoch 6/20, Batch 7/34, Loss: 20.88450050354004, Acc: 0.11607142857142858
tensor(3.3129)
tensor(17.8107)
[TRAIN] Epoch 6/20, Batch 8/34, Loss: 20.914384841918945, Acc: 0.109375
tensor(3.7409)
tensor(16.2750)
[TRAIN] Epoch 6/20, Batch 9/34, Loss: 20.814552307128906, Acc: 0.10416666666666667
tensor(3.6902)
tensor(18.1351)
[TRAIN] Epoch 6/20, Batch 10/34, Loss: 20.915630340576172, Acc: 0.10625
tensor(3.9611)
tensor(19.5372)
[TRAIN] Epoch 6/20, Batch 11/34, Loss: 21.150415420532227, Acc: 0.09659090909090909
tensor(3.4301)
tensor(16.9905)
[TRAIN] Epoch 6/20, Batch 12/34, Loss: 21.089601516723633, Acc: 0.09375
tensor(3.6246)
tensor(14.4593)
[TRAIN] Epoch 6/20, Batch 13/34, Loss: 20.858388900756836, Acc: 0.08653846153846154
tensor(3.8766)
tensor(17.0020)
[TRAIN] Epoch 6/20, Batch 14/34, Loss: 20.85982894897461, Acc: 0.08482142857142858
tensor(4.4459)
tensor(21.5817)
[TRAIN] Epoch 6/20, Batch 15/34, Loss: 21.204349517822266, Acc: 0.07916666666666666
tensor(3.3363)
tensor(19.0072)
[TRAIN] Epoch 6/20, Batch 16/34, Loss: 21.275548934936523, Acc: 0.08203125
tensor(4.5029)
tensor(16.9848)
[TRAIN] Epoch 6/20, Batch 17/34, Loss: 21.288028717041016, Acc: 0.08455882352941177
tensor(3.7155)
tensor(21.8734)
[TRAIN] Epoch 6/20, Batch 18/34, Loss: 21.526966094970703, Acc: 0.08333333333333333
tensor(3.7062)
tensor(22.6378)
[TRAIN] Epoch 6/20, Batch 19/34, Loss: 21.78049659729004, Acc: 0.08552631578947369
tensor(3.7663)
tensor(18.7494)
[TRAIN] Epoch 6/20, Batch 20/34, Loss: 21.8172550201416, Acc: 0.084375
tensor(3.6680)
tensor(16.2069)
[TRAIN] Epoch 6/20, Batch 21/34, Loss: 21.724763870239258, Acc: 0.08333333333333333
tensor(3.3036)
tensor(12.7671)
[TRAIN] Epoch 6/20, Batch 22/34, Loss: 21.46776008605957, Acc: 0.08806818181818182
tensor(3.6388)
tensor(18.4049)
[TRAIN] Epoch 6/20, Batch 23/34, Loss: 21.492801666259766, Acc: 0.08695652173913043
tensor(3.3475)
tensor(18.0701)
[TRAIN] Epoch 6/20, Batch 24/34, Loss: 21.489667892456055, Acc: 0.08333333333333333
tensor(4.3866)
tensor(17.5320)
[TRAIN] Epoch 6/20, Batch 25/34, Loss: 21.506826400756836, Acc: 0.0825
tensor(3.4798)
tensor(19.8993)
[TRAIN] Epoch 6/20, Batch 26/34, Loss: 21.57883644104004, Acc: 0.07932692307692307
tensor(4.1236)
tensor(17.6680)
[TRAIN] Epoch 6/20, Batch 27/34, Loss: 21.58671760559082, Acc: 0.0787037037037037
tensor(4.2444)
tensor(20.8314)
[TRAIN] Epoch 6/20, Batch 28/34, Loss: 21.71132469177246, Acc: 0.078125
tensor(4.0110)
tensor(22.4623)
[TRAIN] Epoch 6/20, Batch 29/34, Loss: 21.875532150268555, Acc: 0.07758620689655173
tensor(3.3445)
tensor(14.0230)
[TRAIN] Epoch 6/20, Batch 30/34, Loss: 21.725263595581055, Acc: 0.07708333333333334
tensor(2.7930)
tensor(14.4193)
[TRAIN] Epoch 6/20, Batch 31/34, Loss: 21.57968521118164, Acc: 0.07862903225806452
tensor(3.3429)
tensor(13.9208)
[TRAIN] Epoch 6/20, Batch 32/34, Loss: 21.44481086730957, Acc: 0.08203125
tensor(3.3860)
tensor(16.5365)
[TRAIN] Epoch 6/20, Batch 33/34, Loss: 21.398679733276367, Acc: 0.08143939393939394
tensor(3.5421)
tensor(11.6125)
[TRAIN] Epoch 6/20, Batch 34/34, Loss: 20.852880477905273, Acc: 0.07904411764705882
tensor(4.2909)
tensor(16.0305)
[TRAIN] Epoch 7/20, Batch 1/34, Loss: 20.32139778137207, Acc: 0.125
tensor(5.3770)
tensor(15.9592)
[TRAIN] Epoch 7/20, Batch 2/34, Loss: 20.828792572021484, Acc: 0.09375
tensor(4.4906)
tensor(19.3104)
[TRAIN] Epoch 7/20, Batch 3/34, Loss: 21.819517135620117, Acc: 0.0625
tensor(4.6797)
tensor(14.7016)
[TRAIN] Epoch 7/20, Batch 4/34, Loss: 21.2099609375, Acc: 0.109375
tensor(3.3860)
tensor(15.1730)
[TRAIN] Epoch 7/20, Batch 5/34, Loss: 20.679767608642578, Acc: 0.1
tensor(3.8090)
tensor(16.1839)
[TRAIN] Epoch 7/20, Batch 6/34, Loss: 20.565275192260742, Acc: 0.09375
tensor(4.1704)
tensor(19.9570)
[TRAIN] Epoch 7/20, Batch 7/34, Loss: 21.07414436340332, Acc: 0.10714285714285714
tensor(2.8199)
tensor(18.5942)
[TRAIN] Epoch 7/20, Batch 8/34, Loss: 21.116634368896484, Acc: 0.1015625
tensor(4.6682)
tensor(16.6675)
[TRAIN] Epoch 7/20, Batch 9/34, Loss: 21.140968322753906, Acc: 0.10416666666666667
tensor(3.8367)
tensor(15.4054)
[TRAIN] Epoch 7/20, Batch 10/34, Loss: 20.951082229614258, Acc: 0.125
tensor(4.7247)
tensor(14.8972)
[TRAIN] Epoch 7/20, Batch 11/34, Loss: 20.830251693725586, Acc: 0.125
tensor(3.7207)
tensor(16.5240)
[TRAIN] Epoch 7/20, Batch 12/34, Loss: 20.781450271606445, Acc: 0.11979166666666667
tensor(3.5243)
tensor(14.8374)
[TRAIN] Epoch 7/20, Batch 13/34, Loss: 20.595319747924805, Acc: 0.11057692307692307
tensor(4.0259)
tensor(18.1765)
[TRAIN] Epoch 7/20, Batch 14/34, Loss: 20.710115432739258, Acc: 0.11160714285714286
tensor(3.4867)
tensor(16.0566)
[TRAIN] Epoch 7/20, Batch 15/34, Loss: 20.632326126098633, Acc: 0.11666666666666667
tensor(3.2359)
tensor(15.5088)
[TRAIN] Epoch 7/20, Batch 16/34, Loss: 20.51434326171875, Acc: 0.11328125
tensor(3.5289)
tensor(14.2372)
[TRAIN] Epoch 7/20, Batch 17/34, Loss: 20.352684020996094, Acc: 0.11764705882352941
tensor(4.0626)
tensor(19.5013)
[TRAIN] Epoch 7/20, Batch 18/34, Loss: 20.53108024597168, Acc: 0.11805555555555555
tensor(3.5056)
tensor(17.9941)
[TRAIN] Epoch 7/20, Batch 19/34, Loss: 20.582061767578125, Acc: 0.11513157894736842
tensor(3.3479)
tensor(17.4634)
[TRAIN] Epoch 7/20, Batch 20/34, Loss: 20.593524932861328, Acc: 0.1125
tensor(3.0484)
tensor(14.7162)
[TRAIN] Epoch 7/20, Batch 21/34, Loss: 20.458816528320312, Acc: 0.1130952380952381
tensor(2.7474)
tensor(16.2722)
[TRAIN] Epoch 7/20, Batch 22/34, Loss: 20.393396377563477, Acc: 0.11079545454545454
tensor(3.7491)
tensor(15.2961)
[TRAIN] Epoch 7/20, Batch 23/34, Loss: 20.33477783203125, Acc: 0.10869565217391304
tensor(3.3407)
tensor(12.2789)
[TRAIN] Epoch 7/20, Batch 24/34, Loss: 20.1383113861084, Acc: 0.10416666666666667
tensor(4.2031)
tensor(17.6569)
[TRAIN] Epoch 7/20, Batch 25/34, Loss: 20.207176208496094, Acc: 0.1
tensor(4.0961)
tensor(18.8541)
[TRAIN] Epoch 7/20, Batch 26/34, Loss: 20.31267547607422, Acc: 0.0985576923076923
tensor(4.6347)
tensor(14.3541)
[TRAIN] Epoch 7/20, Batch 27/34, Loss: 20.263643264770508, Acc: 0.09490740740740741
tensor(3.4094)
tensor(17.7064)
[TRAIN] Epoch 7/20, Batch 28/34, Loss: 20.294076919555664, Acc: 0.09598214285714286
tensor(3.3718)
tensor(18.4735)
[TRAIN] Epoch 7/20, Batch 29/34, Loss: 20.347562789916992, Acc: 0.09482758620689655
tensor(3.2796)
tensor(20.4904)
[TRAIN] Epoch 7/20, Batch 30/34, Loss: 20.46164321899414, Acc: 0.09375
tensor(4.5620)
tensor(11.8922)
[TRAIN] Epoch 7/20, Batch 31/34, Loss: 20.33237075805664, Acc: 0.09274193548387097
tensor(3.8142)
tensor(19.3649)
[TRAIN] Epoch 7/20, Batch 32/34, Loss: 20.421329498291016, Acc: 0.08984375
tensor(3.7049)
tensor(24.2968)
[TRAIN] Epoch 7/20, Batch 33/34, Loss: 20.65103530883789, Acc: 0.0928030303030303
tensor(3.6074)
tensor(21.2102)
[TRAIN] Epoch 7/20, Batch 34/34, Loss: 20.18051528930664, Acc: 0.0900735294117647
tensor(3.9959)
tensor(13.8042)
[TRAIN] Epoch 8/20, Batch 1/34, Loss: 17.80010414123535, Acc: 0.125
tensor(3.1967)
tensor(21.3980)
[TRAIN] Epoch 8/20, Batch 2/34, Loss: 21.197399139404297, Acc: 0.09375
tensor(3.0933)
tensor(22.5531)
[TRAIN] Epoch 8/20, Batch 3/34, Loss: 22.680395126342773, Acc: 0.0625
tensor(3.7659)
tensor(18.5345)
[TRAIN] Epoch 8/20, Batch 4/34, Loss: 22.585386276245117, Acc: 0.046875
tensor(3.3255)
tensor(21.6473)
[TRAIN] Epoch 8/20, Batch 5/34, Loss: 23.062877655029297, Acc: 0.0375
tensor(4.0515)
tensor(15.3785)
[TRAIN] Epoch 8/20, Batch 6/34, Loss: 22.4574031829834, Acc: 0.052083333333333336
tensor(3.8032)
tensor(20.4237)
[TRAIN] Epoch 8/20, Batch 7/34, Loss: 22.710176467895508, Acc: 0.07142857142857142
tensor(3.5441)
tensor(26.9491)
[TRAIN] Epoch 8/20, Batch 8/34, Loss: 23.683061599731445, Acc: 0.0625
tensor(4.0531)
tensor(19.9885)
[TRAIN] Epoch 8/20, Batch 9/34, Loss: 23.722902297973633, Acc: 0.0625
tensor(3.3948)
tensor(20.2378)
[TRAIN] Epoch 8/20, Batch 10/34, Loss: 23.71387481689453, Acc: 0.0625
tensor(3.3546)
tensor(18.1309)
[TRAIN] Epoch 8/20, Batch 11/34, Loss: 23.51129722595215, Acc: 0.056818181818181816
tensor(3.2356)
tensor(24.8173)
[TRAIN] Epoch 8/20, Batch 12/34, Loss: 23.88975715637207, Acc: 0.052083333333333336
tensor(3.0801)
tensor(19.3392)
[TRAIN] Epoch 8/20, Batch 13/34, Loss: 23.776643753051758, Acc: 0.052884615384615384
tensor(3.4466)
tensor(15.2021)
[TRAIN] Epoch 8/20, Batch 14/34, Loss: 23.410356521606445, Acc: 0.05357142857142857
tensor(3.6066)
tensor(16.8037)
[TRAIN] Epoch 8/20, Batch 15/34, Loss: 23.210355758666992, Acc: 0.05416666666666667
tensor(4.7097)
tensor(19.4853)
[TRAIN] Epoch 8/20, Batch 16/34, Loss: 23.271894454956055, Acc: 0.0546875
tensor(3.5311)
tensor(21.8178)
[TRAIN] Epoch 8/20, Batch 17/34, Loss: 23.394075393676758, Acc: 0.05514705882352941
tensor(3.1865)
tensor(17.6004)
[TRAIN] Epoch 8/20, Batch 18/34, Loss: 23.249229431152344, Acc: 0.052083333333333336
tensor(3.3531)
tensor(14.6765)
[TRAIN] Epoch 8/20, Batch 19/34, Loss: 22.974512100219727, Acc: 0.049342105263157895
tensor(4.1118)
tensor(11.6619)
[TRAIN] Epoch 8/20, Batch 20/34, Loss: 22.61447525024414, Acc: 0.053125
tensor(2.8568)
tensor(13.8563)
[TRAIN] Epoch 8/20, Batch 21/34, Loss: 22.33345603942871, Acc: 0.05952380952380952
tensor(3.6951)
tensor(21.4162)
[TRAIN] Epoch 8/20, Batch 22/34, Loss: 22.45972442626953, Acc: 0.05965909090909091
tensor(3.4067)
tensor(19.1787)
[TRAIN] Epoch 8/20, Batch 23/34, Loss: 22.46518898010254, Acc: 0.059782608695652176
tensor(3.6219)
tensor(16.8781)
[TRAIN] Epoch 8/20, Batch 24/34, Loss: 22.383302688598633, Acc: 0.0625
tensor(3.8317)
tensor(17.0554)
[TRAIN] Epoch 8/20, Batch 25/34, Loss: 22.323457717895508, Acc: 0.06
tensor(4.4143)
tensor(15.8901)
[TRAIN] Epoch 8/20, Batch 26/34, Loss: 22.24580192565918, Acc: 0.0625
tensor(3.6770)
tensor(17.4193)
[TRAIN] Epoch 8/20, Batch 27/34, Loss: 22.203231811523438, Acc: 0.0625
tensor(4.4853)
tensor(12.6574)
[TRAIN] Epoch 8/20, Batch 28/34, Loss: 22.02250099182129, Acc: 0.0625
tensor(3.8573)
tensor(16.5992)
[TRAIN] Epoch 8/20, Batch 29/34, Loss: 21.9685001373291, Acc: 0.0625
tensor(3.6910)
tensor(16.7770)
[TRAIN] Epoch 8/20, Batch 30/34, Loss: 21.91848373413086, Acc: 0.06666666666666667
tensor(3.6273)
tensor(13.2188)
[TRAIN] Epoch 8/20, Batch 31/34, Loss: 21.754858016967773, Acc: 0.06854838709677419
tensor(3.6577)
tensor(18.7856)
[TRAIN] Epoch 8/20, Batch 32/34, Loss: 21.776369094848633, Acc: 0.068359375
tensor(3.7674)
tensor(16.2482)
[TRAIN] Epoch 8/20, Batch 33/34, Loss: 21.723012924194336, Acc: 0.07007575757575757
tensor(3.1301)
tensor(20.5735)
[TRAIN] Epoch 8/20, Batch 34/34, Loss: 21.214820861816406, Acc: 0.06801470588235294
tensor(3.4682)
tensor(20.0019)
[TRAIN] Epoch 9/20, Batch 1/34, Loss: 23.470073699951172, Acc: 0.1875
tensor(4.0066)
tensor(17.4917)
[TRAIN] Epoch 9/20, Batch 2/34, Loss: 22.484203338623047, Acc: 0.125
tensor(3.8305)
tensor(19.5082)
[TRAIN] Epoch 9/20, Batch 3/34, Loss: 22.76905059814453, Acc: 0.08333333333333333
tensor(4.0568)
tensor(16.4525)
[TRAIN] Epoch 9/20, Batch 4/34, Loss: 22.204111099243164, Acc: 0.109375
tensor(3.9953)
tensor(15.4089)
[TRAIN] Epoch 9/20, Batch 5/34, Loss: 21.644123077392578, Acc: 0.1125
tensor(3.9575)
tensor(21.0419)
[TRAIN] Epoch 9/20, Batch 6/34, Loss: 22.203338623046875, Acc: 0.10416666666666667
tensor(3.2572)
tensor(22.7370)
[TRAIN] Epoch 9/20, Batch 7/34, Loss: 22.744884490966797, Acc: 0.08928571428571429
tensor(3.7821)
tensor(16.7887)
[TRAIN] Epoch 9/20, Batch 8/34, Loss: 22.473129272460938, Acc: 0.09375
tensor(3.5926)
tensor(16.4781)
[TRAIN] Epoch 9/20, Batch 9/34, Loss: 22.206193923950195, Acc: 0.08333333333333333
tensor(3.1773)
tensor(16.8201)
[TRAIN] Epoch 9/20, Batch 10/34, Loss: 21.985309600830078, Acc: 0.08125
tensor(4.0220)
tensor(21.0317)
[TRAIN] Epoch 9/20, Batch 11/34, Loss: 22.264253616333008, Acc: 0.07954545454545454
tensor(3.0407)
tensor(14.5889)
[TRAIN] Epoch 9/20, Batch 12/34, Loss: 21.878036499023438, Acc: 0.08854166666666667
tensor(3.5226)
tensor(14.5975)
[TRAIN] Epoch 9/20, Batch 13/34, Loss: 21.588960647583008, Acc: 0.09134615384615384
tensor(3.1559)
tensor(11.8854)
[TRAIN] Epoch 9/20, Batch 14/34, Loss: 21.121273040771484, Acc: 0.10267857142857142
tensor(3.8313)
tensor(17.2969)
[TRAIN] Epoch 9/20, Batch 15/34, Loss: 21.12173080444336, Acc: 0.1
tensor(3.5046)
tensor(16.8197)
[TRAIN] Epoch 9/20, Batch 16/34, Loss: 21.071895599365234, Acc: 0.1015625
tensor(3.7367)
tensor(16.9631)
[TRAIN] Epoch 9/20, Batch 17/34, Loss: 21.050004959106445, Acc: 0.09558823529411764
tensor(3.8343)
tensor(17.7344)
[TRAIN] Epoch 9/20, Batch 18/34, Loss: 21.078821182250977, Acc: 0.09375
tensor(3.2179)
tensor(18.2952)
[TRAIN] Epoch 9/20, Batch 19/34, Loss: 21.101675033569336, Acc: 0.09539473684210527
tensor(4.6145)
tensor(19.2866)
[TRAIN] Epoch 9/20, Batch 20/34, Loss: 21.241647720336914, Acc: 0.090625
tensor(3.7207)
tensor(14.2071)
[TRAIN] Epoch 9/20, Batch 21/34, Loss: 21.083845138549805, Acc: 0.09523809523809523
tensor(3.2660)
tensor(15.4994)
[TRAIN] Epoch 9/20, Batch 22/34, Loss: 20.978458404541016, Acc: 0.09659090909090909
tensor(3.6347)
tensor(18.2589)
[TRAIN] Epoch 9/20, Batch 23/34, Loss: 21.01824951171875, Acc: 0.09510869565217392
tensor(3.8805)
tensor(13.2265)
[TRAIN] Epoch 9/20, Batch 24/34, Loss: 20.85527801513672, Acc: 0.10416666666666667
tensor(3.2094)
tensor(15.2121)
[TRAIN] Epoch 9/20, Batch 25/34, Loss: 20.757925033569336, Acc: 0.1025
tensor(3.3703)
tensor(12.8950)
[TRAIN] Epoch 9/20, Batch 26/34, Loss: 20.58513069152832, Acc: 0.10336538461538461
tensor(3.0763)
tensor(11.9465)
[TRAIN] Epoch 9/20, Batch 27/34, Loss: 20.379117965698242, Acc: 0.10416666666666667
tensor(3.5468)
tensor(14.6997)
[TRAIN] Epoch 9/20, Batch 28/34, Loss: 20.302953720092773, Acc: 0.10267857142857142
tensor(4.1699)
tensor(13.1277)
[TRAIN] Epoch 9/20, Batch 29/34, Loss: 20.199321746826172, Acc: 0.10129310344827586
tensor(3.5827)
tensor(12.8205)
[TRAIN] Epoch 9/20, Batch 30/34, Loss: 20.072784423828125, Acc: 0.1
tensor(3.2589)
tensor(15.1606)
[TRAIN] Epoch 9/20, Batch 31/34, Loss: 20.019451141357422, Acc: 0.10080645161290322
tensor(2.9254)
tensor(13.9547)
[TRAIN] Epoch 9/20, Batch 32/34, Loss: 19.92134666442871, Acc: 0.1015625
tensor(3.4774)
tensor(12.4584)
[TRAIN] Epoch 9/20, Batch 33/34, Loss: 19.800569534301758, Acc: 0.09848484848484848
tensor(3.2327)
tensor(20.8062)
[TRAIN] Epoch 9/20, Batch 34/34, Loss: 19.35076904296875, Acc: 0.09558823529411764
tensor(3.3735)
tensor(13.2897)
[TRAIN] Epoch 10/20, Batch 1/34, Loss: 16.663211822509766, Acc: 0.0625
tensor(3.9708)
tensor(14.3410)
[TRAIN] Epoch 10/20, Batch 2/34, Loss: 17.48748207092285, Acc: 0.0625
tensor(4.4597)
tensor(16.0342)
[TRAIN] Epoch 10/20, Batch 3/34, Loss: 18.489608764648438, Acc: 0.08333333333333333
tensor(4.1546)
tensor(18.8947)
[TRAIN] Epoch 10/20, Batch 4/34, Loss: 19.629520416259766, Acc: 0.109375
tensor(3.9798)
tensor(17.4711)
[TRAIN] Epoch 10/20, Batch 5/34, Loss: 19.993806838989258, Acc: 0.1125
tensor(4.2902)
tensor(15.4509)
[TRAIN] Epoch 10/20, Batch 6/34, Loss: 19.951688766479492, Acc: 0.11458333333333333
tensor(3.9590)
tensor(13.3101)
[TRAIN] Epoch 10/20, Batch 7/34, Loss: 19.56846046447754, Acc: 0.11607142857142858
tensor(3.4069)
tensor(13.7821)
[TRAIN] Epoch 10/20, Batch 8/34, Loss: 19.271018981933594, Acc: 0.125
tensor(3.3932)
tensor(12.2828)
[TRAIN] Epoch 10/20, Batch 9/34, Loss: 18.871570587158203, Acc: 0.11805555555555555
tensor(3.2798)
tensor(12.6084)
[TRAIN] Epoch 10/20, Batch 10/34, Loss: 18.5732364654541, Acc: 0.11875
tensor(3.0966)
tensor(15.8391)
[TRAIN] Epoch 10/20, Batch 11/34, Loss: 18.606185913085938, Acc: 0.125
tensor(3.5551)
tensor(15.0474)
[TRAIN] Epoch 10/20, Batch 12/34, Loss: 18.60587501525879, Acc: 0.11979166666666667
tensor(3.5660)
tensor(15.4115)
[TRAIN] Epoch 10/20, Batch 13/34, Loss: 18.634464263916016, Acc: 0.11538461538461539
tensor(3.5223)
tensor(13.2233)
[TRAIN] Epoch 10/20, Batch 14/34, Loss: 18.499542236328125, Acc: 0.12946428571428573
tensor(3.9928)
tensor(14.1882)
[TRAIN] Epoch 10/20, Batch 15/34, Loss: 18.478303909301758, Acc: 0.125
tensor(3.9354)
tensor(20.4509)
[TRAIN] Epoch 10/20, Batch 16/34, Loss: 18.847553253173828, Acc: 0.1171875
tensor(4.0654)
tensor(14.6803)
[TRAIN] Epoch 10/20, Batch 17/34, Loss: 18.841562271118164, Acc: 0.11397058823529412
tensor(3.4857)
tensor(15.8399)
[TRAIN] Epoch 10/20, Batch 18/34, Loss: 18.86844825744629, Acc: 0.1111111111111111
tensor(3.5641)
tensor(15.0561)
[TRAIN] Epoch 10/20, Batch 19/34, Loss: 18.855382919311523, Acc: 0.10855263157894737
tensor(3.4424)
tensor(14.4389)
[TRAIN] Epoch 10/20, Batch 20/34, Loss: 18.806682586669922, Acc: 0.10625
tensor(3.4741)
tensor(14.3451)
[TRAIN] Epoch 10/20, Batch 21/34, Loss: 18.75965690612793, Acc: 0.10714285714285714
tensor(3.5328)
tensor(16.8631)
[TRAIN] Epoch 10/20, Batch 22/34, Loss: 18.83403205871582, Acc: 0.10511363636363637
tensor(3.4670)
tensor(14.9705)
[TRAIN] Epoch 10/20, Batch 23/34, Loss: 18.81679344177246, Acc: 0.10054347826086957
tensor(3.5844)
tensor(12.9139)
[TRAIN] Epoch 10/20, Batch 24/34, Loss: 18.720190048217773, Acc: 0.09895833333333333
tensor(4.6479)
tensor(19.9981)
[TRAIN] Epoch 10/20, Batch 25/34, Loss: 18.95722198486328, Acc: 0.0975
tensor(4.0143)
tensor(14.7561)
[TRAIN] Epoch 10/20, Batch 26/34, Loss: 18.95003890991211, Acc: 0.0985576923076923
tensor(3.9414)
tensor(15.6887)
[TRAIN] Epoch 10/20, Batch 27/34, Loss: 18.97522735595703, Acc: 0.09722222222222222
tensor(3.4052)
tensor(14.3410)
[TRAIN] Epoch 10/20, Batch 28/34, Loss: 18.931333541870117, Acc: 0.09821428571428571
tensor(3.3394)
tensor(14.8721)
[TRAIN] Epoch 10/20, Batch 29/34, Loss: 18.906513214111328, Acc: 0.10344827586206896
tensor(3.2860)
tensor(13.4816)
[TRAIN] Epoch 10/20, Batch 30/34, Loss: 18.835214614868164, Acc: 0.10416666666666667
tensor(2.9544)
tensor(15.3655)
[TRAIN] Epoch 10/20, Batch 31/34, Loss: 18.818592071533203, Acc: 0.10483870967741936
tensor(3.5958)
tensor(14.4195)
[TRAIN] Epoch 10/20, Batch 32/34, Loss: 18.793489456176758, Acc: 0.103515625
tensor(3.1769)
tensor(19.6760)
[TRAIN] Epoch 10/20, Batch 33/34, Loss: 18.916501998901367, Acc: 0.10606060606060606
tensor(4.2581)
tensor(26.8304)
[TRAIN] Epoch 10/20, Batch 34/34, Loss: 18.531578063964844, Acc: 0.10294117647058823
[VAL] Acc: 0.20903954802259886
[TEST] Acc: 0.2768361581920904
tensor(3.2194)
tensor(13.6609)
[TRAIN] Epoch 11/20, Batch 1/34, Loss: 16.880367279052734, Acc: 0.1875
tensor(3.7044)
tensor(17.9514)
[TRAIN] Epoch 11/20, Batch 2/34, Loss: 19.268081665039062, Acc: 0.09375
tensor(3.6662)
tensor(21.5020)
[TRAIN] Epoch 11/20, Batch 3/34, Loss: 21.234786987304688, Acc: 0.10416666666666667
tensor(4.5908)
tensor(14.1409)
[TRAIN] Epoch 11/20, Batch 4/34, Loss: 20.6090087890625, Acc: 0.109375
tensor(3.9181)
tensor(16.0391)
[TRAIN] Epoch 11/20, Batch 5/34, Loss: 20.478656768798828, Acc: 0.1
tensor(3.6276)
tensor(17.0348)
[TRAIN] Epoch 11/20, Batch 6/34, Loss: 20.50926971435547, Acc: 0.09375
tensor(3.8217)
tensor(17.4934)
[TRAIN] Epoch 11/20, Batch 7/34, Loss: 20.6243953704834, Acc: 0.08035714285714286
tensor(3.1110)
tensor(15.6959)
[TRAIN] Epoch 11/20, Batch 8/34, Loss: 20.397201538085938, Acc: 0.078125
tensor(3.0895)
tensor(15.4336)
[TRAIN] Epoch 11/20, Batch 9/34, Loss: 20.188966751098633, Acc: 0.10416666666666667
tensor(3.5544)
tensor(14.7192)
[TRAIN] Epoch 11/20, Batch 10/34, Loss: 19.997425079345703, Acc: 0.11875
tensor(4.1001)
tensor(14.3342)
[TRAIN] Epoch 11/20, Batch 11/34, Loss: 19.855318069458008, Acc: 0.13068181818181818
tensor(3.5412)
tensor(17.0190)
[TRAIN] Epoch 11/20, Batch 12/34, Loss: 19.9140625, Acc: 0.11979166666666667
tensor(3.5787)
tensor(13.1031)
[TRAIN] Epoch 11/20, Batch 13/34, Loss: 19.66543197631836, Acc: 0.12980769230769232
tensor(3.5527)
tensor(16.4685)
[TRAIN] Epoch 11/20, Batch 14/34, Loss: 19.690847396850586, Acc: 0.125
tensor(4.0200)
tensor(11.8014)
[TRAIN] Epoch 11/20, Batch 15/34, Loss: 19.43288230895996, Acc: 0.12916666666666668
tensor(3.5561)
tensor(14.2102)
[TRAIN] Epoch 11/20, Batch 16/34, Loss: 19.328720092773438, Acc: 0.125
tensor(4.4574)
tensor(15.6607)
[TRAIN] Epoch 11/20, Batch 17/34, Loss: 19.375152587890625, Acc: 0.1213235294117647
tensor(3.9019)
tensor(14.4898)
[TRAIN] Epoch 11/20, Batch 18/34, Loss: 19.320512771606445, Acc: 0.12152777777777778
tensor(3.2625)
tensor(14.2576)
[TRAIN] Epoch 11/20, Batch 19/34, Loss: 19.225751876831055, Acc: 0.12171052631578948
tensor(3.7622)
tensor(15.3285)
[TRAIN] Epoch 11/20, Batch 20/34, Loss: 19.218997955322266, Acc: 0.121875
tensor(3.8011)
tensor(17.0027)
[TRAIN] Epoch 11/20, Batch 21/34, Loss: 19.294462203979492, Acc: 0.11904761904761904
tensor(3.2007)
tensor(17.2289)
[TRAIN] Epoch 11/20, Batch 22/34, Loss: 19.346057891845703, Acc: 0.11363636363636363
tensor(3.3975)
tensor(15.4367)
[TRAIN] Epoch 11/20, Batch 23/34, Loss: 19.32380485534668, Acc: 0.10869565217391304
tensor(3.5147)
tensor(20.5502)
[TRAIN] Epoch 11/20, Batch 24/34, Loss: 19.521350860595703, Acc: 0.10677083333333333
tensor(3.5238)
tensor(16.7533)
[TRAIN] Epoch 11/20, Batch 25/34, Loss: 19.55158042907715, Acc: 0.105
tensor(3.7869)
tensor(15.4208)
[TRAIN] Epoch 11/20, Batch 26/34, Loss: 19.53835678100586, Acc: 0.10336538461538461
tensor(2.9528)
tensor(12.3921)
[TRAIN] Epoch 11/20, Batch 27/34, Loss: 19.383041381835938, Acc: 0.10648148148148148
tensor(3.1339)
tensor(17.1346)
[TRAIN] Epoch 11/20, Batch 28/34, Loss: 19.414663314819336, Acc: 0.10491071428571429
tensor(3.7749)
tensor(14.3532)
[TRAIN] Epoch 11/20, Batch 29/34, Loss: 19.370302200317383, Acc: 0.10775862068965517
tensor(3.6540)
tensor(13.2343)
[TRAIN] Epoch 11/20, Batch 30/34, Loss: 19.28757095336914, Acc: 0.10833333333333334
tensor(3.4215)
tensor(11.8095)
[TRAIN] Epoch 11/20, Batch 31/34, Loss: 19.156715393066406, Acc: 0.10887096774193548
tensor(3.2160)
tensor(12.8552)
[TRAIN] Epoch 11/20, Batch 32/34, Loss: 19.060293197631836, Acc: 0.109375
tensor(3.3400)
tensor(15.4805)
[TRAIN] Epoch 11/20, Batch 33/34, Loss: 19.05302619934082, Acc: 0.10795454545454546
tensor(4.2933)
tensor(22.2710)
[TRAIN] Epoch 11/20, Batch 34/34, Loss: 18.639137268066406, Acc: 0.10477941176470588
tensor(2.9264)
tensor(16.5487)
[TRAIN] Epoch 12/20, Batch 1/34, Loss: 19.475126266479492, Acc: 0.0625
tensor(3.4207)
tensor(15.8939)
[TRAIN] Epoch 12/20, Batch 2/34, Loss: 19.39488983154297, Acc: 0.125
tensor(3.3429)
tensor(12.5527)
[TRAIN] Epoch 12/20, Batch 3/34, Loss: 18.22845458984375, Acc: 0.10416666666666667
tensor(3.7656)
tensor(17.7068)
[TRAIN] Epoch 12/20, Batch 4/34, Loss: 19.039451599121094, Acc: 0.109375
tensor(3.8738)
tensor(17.7596)
[TRAIN] Epoch 12/20, Batch 5/34, Loss: 19.558238983154297, Acc: 0.125
tensor(3.1411)
tensor(13.5331)
[TRAIN] Epoch 12/20, Batch 6/34, Loss: 19.077552795410156, Acc: 0.13541666666666666
tensor(3.6578)
tensor(15.8672)
[TRAIN] Epoch 12/20, Batch 7/34, Loss: 19.14146614074707, Acc: 0.14285714285714285
tensor(3.5023)
tensor(13.0366)
[TRAIN] Epoch 12/20, Batch 8/34, Loss: 18.816146850585938, Acc: 0.15625
tensor(2.9686)
tensor(19.3964)
[TRAIN] Epoch 12/20, Batch 9/34, Loss: 19.210458755493164, Acc: 0.1388888888888889
tensor(3.5497)
tensor(17.9863)
[TRAIN] Epoch 12/20, Batch 10/34, Loss: 19.443016052246094, Acc: 0.13125
tensor(3.7181)
tensor(16.1893)
[TRAIN] Epoch 12/20, Batch 11/34, Loss: 19.4852352142334, Acc: 0.125
tensor(3.5556)
tensor(18.5880)
[TRAIN] Epoch 12/20, Batch 12/34, Loss: 19.706764221191406, Acc: 0.125
tensor(3.7001)
tensor(14.0355)
[TRAIN] Epoch 12/20, Batch 13/34, Loss: 19.555139541625977, Acc: 0.125
tensor(3.7840)
tensor(14.1348)
[TRAIN] Epoch 12/20, Batch 14/34, Loss: 19.438262939453125, Acc: 0.13392857142857142
tensor(3.7360)
tensor(15.2826)
[TRAIN] Epoch 12/20, Batch 15/34, Loss: 19.410282135009766, Acc: 0.125
tensor(3.3938)
tensor(17.6833)
[TRAIN] Epoch 12/20, Batch 16/34, Loss: 19.51445960998535, Acc: 0.12890625
tensor(2.9068)
tensor(18.2057)
[TRAIN] Epoch 12/20, Batch 17/34, Loss: 19.608463287353516, Acc: 0.125
tensor(3.0743)
tensor(17.8609)
[TRAIN] Epoch 12/20, Batch 18/34, Loss: 19.68216896057129, Acc: 0.12152777777777778
tensor(3.3307)
tensor(15.8066)
[TRAIN] Epoch 12/20, Batch 19/34, Loss: 19.65349006652832, Acc: 0.12171052631578948
tensor(3.2628)
tensor(12.3884)
[TRAIN] Epoch 12/20, Batch 20/34, Loss: 19.453378677368164, Acc: 0.13125
tensor(3.2540)
tensor(14.8797)
[TRAIN] Epoch 12/20, Batch 21/34, Loss: 19.39053726196289, Acc: 0.125
tensor(3.7629)
tensor(15.9225)
[TRAIN] Epoch 12/20, Batch 22/34, Loss: 19.4039363861084, Acc: 0.12215909090909091
tensor(3.2135)
tensor(17.3537)
[TRAIN] Epoch 12/20, Batch 23/34, Loss: 19.45451545715332, Acc: 0.12228260869565218
tensor(3.2913)
tensor(17.3200)
[TRAIN] Epoch 12/20, Batch 24/34, Loss: 19.50271224975586, Acc: 0.11979166666666667
tensor(3.2617)
tensor(15.5850)
[TRAIN] Epoch 12/20, Batch 25/34, Loss: 19.476472854614258, Acc: 0.115
tensor(3.3362)
tensor(16.7929)
[TRAIN] Epoch 12/20, Batch 26/34, Loss: 19.501569747924805, Acc: 0.11298076923076923
tensor(2.9709)
tensor(19.0837)
[TRAIN] Epoch 12/20, Batch 27/34, Loss: 19.596126556396484, Acc: 0.11342592592592593
tensor(3.5767)
tensor(15.7002)
[TRAIN] Epoch 12/20, Batch 28/34, Loss: 19.584728240966797, Acc: 0.11607142857142858
tensor(3.4033)
tensor(15.7575)
[TRAIN] Epoch 12/20, Batch 29/34, Loss: 19.57010841369629, Acc: 0.11422413793103449
tensor(3.0235)
tensor(13.8491)
[TRAIN] Epoch 12/20, Batch 30/34, Loss: 19.480192184448242, Acc: 0.11666666666666667
tensor(3.1111)
tensor(16.0795)
[TRAIN] Epoch 12/20, Batch 31/34, Loss: 19.470848083496094, Acc: 0.11491935483870967
tensor(3.2907)
tensor(19.2861)
[TRAIN] Epoch 12/20, Batch 32/34, Loss: 19.567907333374023, Acc: 0.115234375
tensor(3.2100)
tensor(19.1482)
[TRAIN] Epoch 12/20, Batch 33/34, Loss: 19.6524600982666, Acc: 0.11363636363636363
tensor(2.8338)
tensor(27.3402)
[TRAIN] Epoch 12/20, Batch 34/34, Loss: 19.240846633911133, Acc: 0.11029411764705882
tensor(3.3206)
tensor(14.5676)
[TRAIN] Epoch 13/20, Batch 1/34, Loss: 17.88816261291504, Acc: 0.125
tensor(3.8603)
tensor(15.1930)
[TRAIN] Epoch 13/20, Batch 2/34, Loss: 18.470745086669922, Acc: 0.09375
tensor(3.5765)
tensor(19.2109)
[TRAIN] Epoch 13/20, Batch 3/34, Loss: 19.909631729125977, Acc: 0.08333333333333333
tensor(3.3730)
tensor(18.0923)
[TRAIN] Epoch 13/20, Batch 4/34, Loss: 20.298561096191406, Acc: 0.09375
tensor(3.4696)
tensor(18.4410)
[TRAIN] Epoch 13/20, Batch 5/34, Loss: 20.620975494384766, Acc: 0.0875
tensor(3.2187)
tensor(15.8818)
[TRAIN] Epoch 13/20, Batch 6/34, Loss: 20.36756134033203, Acc: 0.07291666666666667
tensor(3.6943)
tensor(16.5583)
[TRAIN] Epoch 13/20, Batch 7/34, Loss: 20.35112953186035, Acc: 0.08928571428571429
tensor(3.6277)
tensor(15.5038)
[TRAIN] Epoch 13/20, Batch 8/34, Loss: 20.19867706298828, Acc: 0.1015625
tensor(3.6687)
tensor(18.3854)
[TRAIN] Epoch 13/20, Batch 9/34, Loss: 20.40484046936035, Acc: 0.10416666666666667
tensor(3.3219)
tensor(14.6982)
[TRAIN] Epoch 13/20, Batch 10/34, Loss: 20.166366577148438, Acc: 0.11875
tensor(3.5348)
tensor(15.1653)
[TRAIN] Epoch 13/20, Batch 11/34, Loss: 20.03306770324707, Acc: 0.11931818181818182
tensor(3.3830)
tensor(16.4318)
[TRAIN] Epoch 13/20, Batch 12/34, Loss: 20.01487922668457, Acc: 0.11458333333333333
tensor(3.7951)
tensor(17.9679)
[TRAIN] Epoch 13/20, Batch 13/34, Loss: 20.14934539794922, Acc: 0.10576923076923077
tensor(3.5357)
tensor(21.3107)
[TRAIN] Epoch 13/20, Batch 14/34, Loss: 20.484853744506836, Acc: 0.10714285714285714
tensor(3.7787)
tensor(15.5614)
[TRAIN] Epoch 13/20, Batch 15/34, Loss: 20.408533096313477, Acc: 0.10416666666666667
tensor(3.3734)
tensor(20.7484)
[TRAIN] Epoch 13/20, Batch 16/34, Loss: 20.640613555908203, Acc: 0.10546875
tensor(3.4729)
tensor(15.4438)
[TRAIN] Epoch 13/20, Batch 17/34, Loss: 20.539201736450195, Acc: 0.10661764705882353
tensor(3.3508)
tensor(17.0787)
[TRAIN] Epoch 13/20, Batch 18/34, Loss: 20.53310775756836, Acc: 0.1076388888888889
tensor(3.4346)
tensor(16.1119)
[TRAIN] Epoch 13/20, Batch 19/34, Loss: 20.481185913085938, Acc: 0.11513157894736842
tensor(3.9066)
tensor(14.3628)
[TRAIN] Epoch 13/20, Batch 20/34, Loss: 20.37059783935547, Acc: 0.115625
tensor(3.4981)
tensor(14.4783)
[TRAIN] Epoch 13/20, Batch 21/34, Loss: 20.256589889526367, Acc: 0.11904761904761904
tensor(3.1422)
tensor(16.4705)
[TRAIN] Epoch 13/20, Batch 22/34, Loss: 20.22732162475586, Acc: 0.11931818181818182
tensor(3.9538)
tensor(15.1472)
[TRAIN] Epoch 13/20, Batch 23/34, Loss: 20.178346633911133, Acc: 0.11684782608695653
tensor(3.4503)
tensor(17.2209)
[TRAIN] Epoch 13/20, Batch 24/34, Loss: 20.198881149291992, Acc: 0.1171875
tensor(3.8419)
tensor(15.1945)
[TRAIN] Epoch 13/20, Batch 25/34, Loss: 20.152381896972656, Acc: 0.12
tensor(3.2525)
tensor(12.2528)
[TRAIN] Epoch 13/20, Batch 26/34, Loss: 19.973649978637695, Acc: 0.125
tensor(3.5562)
tensor(14.4591)
[TRAIN] Epoch 13/20, Batch 27/34, Loss: 19.901119232177734, Acc: 0.12731481481481483
tensor(3.3355)
tensor(15.6323)
[TRAIN] Epoch 13/20, Batch 28/34, Loss: 19.867786407470703, Acc: 0.125
tensor(3.6055)
tensor(15.8382)
[TRAIN] Epoch 13/20, Batch 29/34, Loss: 19.85316276550293, Acc: 0.125
tensor(3.2960)
tensor(14.4917)
[TRAIN] Epoch 13/20, Batch 30/34, Loss: 19.784311294555664, Acc: 0.12291666666666666
tensor(3.3577)
tensor(16.9873)
[TRAIN] Epoch 13/20, Batch 31/34, Loss: 19.802396774291992, Acc: 0.12096774193548387
tensor(3.5105)
tensor(17.2927)
[TRAIN] Epoch 13/20, Batch 32/34, Loss: 19.83367347717285, Acc: 0.1171875
tensor(3.0487)
tensor(17.8220)
[TRAIN] Epoch 13/20, Batch 33/34, Loss: 19.86509895324707, Acc: 0.11931818181818182
tensor(3.8832)
tensor(18.1115)
[TRAIN] Epoch 13/20, Batch 34/34, Loss: 19.40212631225586, Acc: 0.11580882352941177
tensor(3.3962)
tensor(12.9215)
[TRAIN] Epoch 14/20, Batch 1/34, Loss: 16.317684173583984, Acc: 0.125
tensor(3.8439)
tensor(19.6807)
[TRAIN] Epoch 14/20, Batch 2/34, Loss: 19.92113494873047, Acc: 0.125
tensor(3.4949)
tensor(16.5922)
[TRAIN] Epoch 14/20, Batch 3/34, Loss: 19.9764461517334, Acc: 0.14583333333333334
tensor(3.9464)
tensor(18.0589)
[TRAIN] Epoch 14/20, Batch 4/34, Loss: 20.483652114868164, Acc: 0.125
tensor(4.0631)
tensor(17.9037)
[TRAIN] Epoch 14/20, Batch 5/34, Loss: 20.78029441833496, Acc: 0.125
tensor(4.1078)
tensor(12.3507)
[TRAIN] Epoch 14/20, Batch 6/34, Loss: 20.059986114501953, Acc: 0.125
tensor(3.1608)
tensor(13.2105)
[TRAIN] Epoch 14/20, Batch 7/34, Loss: 19.533035278320312, Acc: 0.13392857142857142
tensor(3.2941)
tensor(14.2932)
[TRAIN] Epoch 14/20, Batch 8/34, Loss: 19.289813995361328, Acc: 0.1484375
tensor(3.4097)
tensor(19.8497)
[TRAIN] Epoch 14/20, Batch 9/34, Loss: 19.730873107910156, Acc: 0.14583333333333334
tensor(3.5483)
tensor(13.7100)
[TRAIN] Epoch 14/20, Batch 10/34, Loss: 19.48361587524414, Acc: 0.15
tensor(4.2913)
tensor(15.4448)
[TRAIN] Epoch 14/20, Batch 11/34, Loss: 19.506563186645508, Acc: 0.1534090909090909
tensor(3.5369)
tensor(14.1708)
[TRAIN] Epoch 14/20, Batch 12/34, Loss: 19.356653213500977, Acc: 0.14583333333333334
tensor(3.2856)
tensor(16.8989)
[TRAIN] Epoch 14/20, Batch 13/34, Loss: 19.420331954956055, Acc: 0.14423076923076922
tensor(3.4489)
tensor(14.9793)
[TRAIN] Epoch 14/20, Batch 14/34, Loss: 19.349472045898438, Acc: 0.13392857142857142
tensor(3.4659)
tensor(16.8009)
[TRAIN] Epoch 14/20, Batch 15/34, Loss: 19.41062355041504, Acc: 0.1375
tensor(3.2218)
tensor(16.7986)
[TRAIN] Epoch 14/20, Batch 16/34, Loss: 19.44873809814453, Acc: 0.1328125
tensor(3.6716)
tensor(16.4794)
[TRAIN] Epoch 14/20, Batch 17/34, Loss: 19.490047454833984, Acc: 0.125
tensor(3.3636)
tensor(14.4507)
[TRAIN] Epoch 14/20, Batch 18/34, Loss: 19.39695167541504, Acc: 0.13194444444444445
tensor(3.8264)
tensor(14.7609)
[TRAIN] Epoch 14/20, Batch 19/34, Loss: 19.354339599609375, Acc: 0.12828947368421054
tensor(3.1263)
tensor(18.5557)
[TRAIN] Epoch 14/20, Batch 20/34, Loss: 19.47072410583496, Acc: 0.121875
tensor(3.4745)
tensor(17.0817)
[TRAIN] Epoch 14/20, Batch 21/34, Loss: 19.522415161132812, Acc: 0.11904761904761904
tensor(3.5864)
tensor(15.7666)
[TRAIN] Epoch 14/20, Batch 22/34, Loss: 19.51471519470215, Acc: 0.12215909090909091
tensor(2.9888)
tensor(15.3544)
[TRAIN] Epoch 14/20, Batch 23/34, Loss: 19.463777542114258, Acc: 0.12228260869565218
tensor(3.1803)
tensor(17.1067)
[TRAIN] Epoch 14/20, Batch 24/34, Loss: 19.498075485229492, Acc: 0.11979166666666667
tensor(3.1540)
tensor(12.1417)
[TRAIN] Epoch 14/20, Batch 25/34, Loss: 19.329980850219727, Acc: 0.1275
tensor(3.5082)
tensor(13.2783)
[TRAIN] Epoch 14/20, Batch 26/34, Loss: 19.232158660888672, Acc: 0.12980769230769232
tensor(3.3431)
tensor(14.6556)
[TRAIN] Epoch 14/20, Batch 27/34, Loss: 19.186473846435547, Acc: 0.12731481481481483
tensor(3.4176)
tensor(13.9054)
[TRAIN] Epoch 14/20, Batch 28/34, Loss: 19.119918823242188, Acc: 0.13392857142857142
tensor(3.5239)
tensor(13.9265)
[TRAIN] Epoch 14/20, Batch 29/34, Loss: 19.062349319458008, Acc: 0.13793103448275862
tensor(3.2756)
tensor(15.5546)
[TRAIN] Epoch 14/20, Batch 30/34, Loss: 19.054607391357422, Acc: 0.1375
tensor(3.7741)
tensor(15.8005)
[TRAIN] Epoch 14/20, Batch 31/34, Loss: 19.071378707885742, Acc: 0.13911290322580644
tensor(3.8380)
tensor(17.6375)
[TRAIN] Epoch 14/20, Batch 32/34, Loss: 19.146509170532227, Acc: 0.13671875
tensor(3.5181)
tensor(14.8672)
[TRAIN] Epoch 14/20, Batch 33/34, Loss: 19.123443603515625, Acc: 0.13636363636363635
tensor(2.8969)
tensor(9.9191)
[TRAIN] Epoch 14/20, Batch 34/34, Loss: 18.63166618347168, Acc: 0.1323529411764706
tensor(3.4170)
tensor(14.2121)
[TRAIN] Epoch 15/20, Batch 1/34, Loss: 17.62906265258789, Acc: 0.0625
tensor(3.3122)
tensor(15.3112)
[TRAIN] Epoch 15/20, Batch 2/34, Loss: 18.12622833251953, Acc: 0.0625
tensor(3.6315)
tensor(16.7804)
[TRAIN] Epoch 15/20, Batch 3/34, Loss: 18.888145446777344, Acc: 0.041666666666666664
tensor(3.1565)
tensor(16.0046)
[TRAIN] Epoch 15/20, Batch 4/34, Loss: 18.95639419555664, Acc: 0.046875
tensor(2.9518)
tensor(12.8102)
[TRAIN] Epoch 15/20, Batch 5/34, Loss: 18.317516326904297, Acc: 0.075
tensor(3.5040)
tensor(14.1920)
[TRAIN] Epoch 15/20, Batch 6/34, Loss: 18.21393585205078, Acc: 0.0625
tensor(2.9626)
tensor(14.4821)
[TRAIN] Epoch 15/20, Batch 7/34, Loss: 18.10404396057129, Acc: 0.0625
tensor(3.8413)
tensor(16.3405)
[TRAIN] Epoch 15/20, Batch 8/34, Loss: 18.3637638092041, Acc: 0.0703125
tensor(3.3386)
tensor(14.3980)
[TRAIN] Epoch 15/20, Batch 9/34, Loss: 18.29407501220703, Acc: 0.08333333333333333
tensor(3.5063)
tensor(17.2091)
[TRAIN] Epoch 15/20, Batch 10/34, Loss: 18.536203384399414, Acc: 0.08125
tensor(3.2942)
tensor(16.6613)
[TRAIN] Epoch 15/20, Batch 11/34, Loss: 18.665237426757812, Acc: 0.08522727272727272
tensor(3.1485)
tensor(15.1488)
[TRAIN] Epoch 15/20, Batch 12/34, Loss: 18.634571075439453, Acc: 0.08333333333333333
tensor(3.1900)
tensor(13.0471)
[TRAIN] Epoch 15/20, Batch 13/34, Loss: 18.450153350830078, Acc: 0.08653846153846154
tensor(3.5569)
tensor(11.2425)
[TRAIN] Epoch 15/20, Batch 14/34, Loss: 18.18938636779785, Acc: 0.08928571428571429
tensor(3.5909)
tensor(12.9920)
[TRAIN] Epoch 15/20, Batch 15/34, Loss: 18.082292556762695, Acc: 0.0875
tensor(3.2372)
tensor(15.1452)
[TRAIN] Epoch 15/20, Batch 16/34, Loss: 18.101049423217773, Acc: 0.0859375
tensor(2.9873)
tensor(14.8502)
[TRAIN] Epoch 15/20, Batch 17/34, Loss: 18.085548400878906, Acc: 0.09926470588235294
tensor(3.3279)
tensor(13.8256)
[TRAIN] Epoch 15/20, Batch 18/34, Loss: 18.033767700195312, Acc: 0.10416666666666667
tensor(3.6451)
tensor(14.5518)
[TRAIN] Epoch 15/20, Batch 19/34, Loss: 18.042354583740234, Acc: 0.10526315789473684
tensor(3.2807)
tensor(13.3400)
[TRAIN] Epoch 15/20, Batch 20/34, Loss: 17.97127342224121, Acc: 0.10625
tensor(3.1188)
tensor(13.0605)
[TRAIN] Epoch 15/20, Batch 21/34, Loss: 17.885942459106445, Acc: 0.10119047619047619
tensor(3.2008)
tensor(14.7320)
[TRAIN] Epoch 15/20, Batch 22/34, Loss: 17.88807487487793, Acc: 0.09943181818181818
tensor(3.2291)
tensor(13.0953)
[TRAIN] Epoch 15/20, Batch 23/34, Loss: 17.820085525512695, Acc: 0.10597826086956522
tensor(3.6646)
tensor(14.3676)
[TRAIN] Epoch 15/20, Batch 24/34, Loss: 17.82892417907715, Acc: 0.10677083333333333
tensor(3.4711)
tensor(17.1708)
[TRAIN] Epoch 15/20, Batch 25/34, Loss: 17.941444396972656, Acc: 0.1075
tensor(3.4556)
tensor(19.3065)
[TRAIN] Epoch 15/20, Batch 26/34, Loss: 18.126853942871094, Acc: 0.10817307692307693
tensor(2.8668)
tensor(13.4643)
[TRAIN] Epoch 15/20, Batch 27/34, Loss: 18.060346603393555, Acc: 0.1087962962962963
tensor(3.5746)
tensor(16.8748)
[TRAIN] Epoch 15/20, Batch 28/34, Loss: 18.14566993713379, Acc: 0.10714285714285714
tensor(3.2239)
tensor(15.4898)
[TRAIN] Epoch 15/20, Batch 29/34, Loss: 18.165258407592773, Acc: 0.10775862068965517
tensor(3.6150)
tensor(14.3194)
[TRAIN] Epoch 15/20, Batch 30/34, Loss: 18.157562255859375, Acc: 0.1125
tensor(3.1865)
tensor(13.3819)
[TRAIN] Epoch 15/20, Batch 31/34, Loss: 18.106300354003906, Acc: 0.11088709677419355
tensor(3.3131)
tensor(14.7766)
[TRAIN] Epoch 15/20, Batch 32/34, Loss: 18.10578155517578, Acc: 0.115234375
tensor(3.4544)
tensor(16.1356)
[TRAIN] Epoch 15/20, Batch 33/34, Loss: 18.150758743286133, Acc: 0.11931818181818182
tensor(3.6309)
tensor(8.0163)
[TRAIN] Epoch 15/20, Batch 34/34, Loss: 17.681142807006836, Acc: 0.11580882352941177
[VAL] Acc: 0.22598870056497175
[TEST] Acc: 0.3163841807909605
tensor(2.9647)
tensor(13.4611)
[TRAIN] Epoch 16/20, Batch 1/34, Loss: 16.425771713256836, Acc: 0.3125
tensor(3.1791)
tensor(15.2739)
[TRAIN] Epoch 16/20, Batch 2/34, Loss: 17.439373016357422, Acc: 0.25
tensor(3.4729)
tensor(15.8007)
[TRAIN] Epoch 16/20, Batch 3/34, Loss: 18.050811767578125, Acc: 0.16666666666666666
tensor(2.9994)
tensor(12.3638)
[TRAIN] Epoch 16/20, Batch 4/34, Loss: 17.378908157348633, Acc: 0.171875
tensor(4.4622)
tensor(14.6175)
[TRAIN] Epoch 16/20, Batch 5/34, Loss: 17.719074249267578, Acc: 0.1375
tensor(3.9199)
tensor(12.0460)
[TRAIN] Epoch 16/20, Batch 6/34, Loss: 17.426877975463867, Acc: 0.125
tensor(3.4241)
tensor(14.6496)
[TRAIN] Epoch 16/20, Batch 7/34, Loss: 17.5192813873291, Acc: 0.11607142857142858
tensor(3.7693)
tensor(16.8590)
[TRAIN] Epoch 16/20, Batch 8/34, Loss: 17.907917022705078, Acc: 0.1171875
tensor(3.6924)
tensor(15.9856)
[TRAIN] Epoch 16/20, Batch 9/34, Loss: 18.10459327697754, Acc: 0.125
tensor(3.0190)
tensor(12.5457)
[TRAIN] Epoch 16/20, Batch 10/34, Loss: 17.850605010986328, Acc: 0.13125
tensor(3.5734)
tensor(18.8902)
[TRAIN] Epoch 16/20, Batch 11/34, Loss: 18.269969940185547, Acc: 0.13068181818181818
tensor(3.6695)
tensor(15.4798)
[TRAIN] Epoch 16/20, Batch 12/34, Loss: 18.343250274658203, Acc: 0.140625
tensor(3.0867)
tensor(13.3536)
[TRAIN] Epoch 16/20, Batch 13/34, Loss: 18.19687271118164, Acc: 0.14903846153846154
tensor(3.8993)
tensor(14.0283)
[TRAIN] Epoch 16/20, Batch 14/34, Loss: 18.177642822265625, Acc: 0.15178571428571427
tensor(3.3616)
tensor(11.5128)
[TRAIN] Epoch 16/20, Batch 15/34, Loss: 17.957427978515625, Acc: 0.1625
tensor(2.8273)
tensor(11.4146)
[TRAIN] Epoch 16/20, Batch 16/34, Loss: 17.725208282470703, Acc: 0.16015625
tensor(2.9486)
tensor(15.8133)
[TRAIN] Epoch 16/20, Batch 17/34, Loss: 17.78619384765625, Acc: 0.15441176470588236
tensor(3.5013)
tensor(17.7739)
[TRAIN] Epoch 16/20, Batch 18/34, Loss: 17.980030059814453, Acc: 0.14930555555555555
tensor(3.3642)
tensor(14.5714)
[TRAIN] Epoch 16/20, Batch 19/34, Loss: 17.977693557739258, Acc: 0.1513157894736842
tensor(3.1952)
tensor(13.3276)
[TRAIN] Epoch 16/20, Batch 20/34, Loss: 17.904949188232422, Acc: 0.146875
tensor(3.2779)
tensor(12.3656)
[TRAIN] Epoch 16/20, Batch 21/34, Loss: 17.79726219177246, Acc: 0.14583333333333334
tensor(3.7329)
tensor(12.1070)
[TRAIN] Epoch 16/20, Batch 22/34, Loss: 17.708290100097656, Acc: 0.14488636363636365
tensor(3.6473)
tensor(12.6683)
[TRAIN] Epoch 16/20, Batch 23/34, Loss: 17.647741317749023, Acc: 0.14673913043478262
tensor(3.9703)
tensor(17.0996)
[TRAIN] Epoch 16/20, Batch 24/34, Loss: 17.790328979492188, Acc: 0.140625
tensor(3.0383)
tensor(18.0674)
[TRAIN] Epoch 16/20, Batch 25/34, Loss: 17.922945022583008, Acc: 0.1375
tensor(3.7691)
tensor(15.5116)
[TRAIN] Epoch 16/20, Batch 26/34, Loss: 17.97516441345215, Acc: 0.1346153846153846
tensor(2.9599)
tensor(14.7247)
[TRAIN] Epoch 16/20, Batch 27/34, Loss: 17.96440315246582, Acc: 0.1412037037037037
tensor(3.0329)
tensor(19.9976)
[TRAIN] Epoch 16/20, Batch 28/34, Loss: 18.14533805847168, Acc: 0.13616071428571427
tensor(3.9308)
tensor(20.5403)
[TRAIN] Epoch 16/20, Batch 29/34, Loss: 18.363468170166016, Acc: 0.1314655172413793
tensor(3.9041)
tensor(18.0384)
[TRAIN] Epoch 16/20, Batch 30/34, Loss: 18.48276710510254, Acc: 0.12708333333333333
tensor(3.7945)
tensor(13.9497)
[TRAIN] Epoch 16/20, Batch 31/34, Loss: 18.45894432067871, Acc: 0.125
tensor(3.4026)
tensor(16.7202)
[TRAIN] Epoch 16/20, Batch 32/34, Loss: 18.510942459106445, Acc: 0.12890625
tensor(3.4425)
tensor(16.8011)
[TRAIN] Epoch 16/20, Batch 33/34, Loss: 18.563446044921875, Acc: 0.125
tensor(3.8341)
tensor(13.1026)
[TRAIN] Epoch 16/20, Batch 34/34, Loss: 18.11086082458496, Acc: 0.1213235294117647
tensor(3.1085)
tensor(14.0547)
[TRAIN] Epoch 17/20, Batch 1/34, Loss: 17.163236618041992, Acc: 0.3125
tensor(2.9222)
tensor(18.1178)
[TRAIN] Epoch 17/20, Batch 2/34, Loss: 19.101577758789062, Acc: 0.1875
tensor(3.5181)
tensor(20.5407)
[TRAIN] Epoch 17/20, Batch 3/34, Loss: 20.75398826599121, Acc: 0.125
tensor(3.3334)
tensor(21.5438)
[TRAIN] Epoch 17/20, Batch 4/34, Loss: 21.78479766845703, Acc: 0.09375
tensor(3.4772)
tensor(15.7052)
[TRAIN] Epoch 17/20, Batch 5/34, Loss: 21.264326095581055, Acc: 0.075
tensor(4.0349)
tensor(15.2379)
[TRAIN] Epoch 17/20, Batch 6/34, Loss: 20.932405471801758, Acc: 0.09375
tensor(3.9562)
tensor(17.1203)
[TRAIN] Epoch 17/20, Batch 7/34, Loss: 20.95298957824707, Acc: 0.10714285714285714
tensor(4.0388)
tensor(17.9442)
[TRAIN] Epoch 17/20, Batch 8/34, Loss: 21.08173942565918, Acc: 0.1171875
tensor(3.9411)
tensor(19.6195)
[TRAIN] Epoch 17/20, Batch 9/34, Loss: 21.35717010498047, Acc: 0.125
tensor(3.9562)
tensor(13.7402)
[TRAIN] Epoch 17/20, Batch 10/34, Loss: 20.991090774536133, Acc: 0.125
tensor(3.5860)
tensor(16.9561)
[TRAIN] Epoch 17/20, Batch 11/34, Loss: 20.95027732849121, Acc: 0.11931818181818182
tensor(3.2121)
tensor(15.8091)
[TRAIN] Epoch 17/20, Batch 12/34, Loss: 20.789518356323242, Acc: 0.109375
tensor(3.1547)
tensor(21.5833)
[TRAIN] Epoch 17/20, Batch 13/34, Loss: 21.093250274658203, Acc: 0.10096153846153846
tensor(3.3734)
tensor(18.7707)
[TRAIN] Epoch 17/20, Batch 14/34, Loss: 21.168306350708008, Acc: 0.10267857142857142
tensor(3.8542)
tensor(15.3481)
[TRAIN] Epoch 17/20, Batch 15/34, Loss: 21.03723907470703, Acc: 0.1
tensor(3.7702)
tensor(14.4829)
[TRAIN] Epoch 17/20, Batch 16/34, Loss: 20.863231658935547, Acc: 0.109375
tensor(4.0895)
tensor(18.4655)
[TRAIN] Epoch 17/20, Batch 17/34, Loss: 20.96274757385254, Acc: 0.11029411764705882
tensor(3.8208)
tensor(15.0254)
[TRAIN] Epoch 17/20, Batch 18/34, Loss: 20.845165252685547, Acc: 0.11805555555555555
tensor(3.3184)
tensor(14.6316)
[TRAIN] Epoch 17/20, Batch 19/34, Loss: 20.69278907775879, Acc: 0.11513157894736842
tensor(3.2128)
tensor(16.0478)
[TRAIN] Epoch 17/20, Batch 20/34, Loss: 20.621177673339844, Acc: 0.1125
tensor(3.2960)
tensor(16.2817)
[TRAIN] Epoch 17/20, Batch 21/34, Loss: 20.571489334106445, Acc: 0.10714285714285714
tensor(3.2687)
tensor(16.4220)
[TRAIN] Epoch 17/20, Batch 22/34, Loss: 20.531455993652344, Acc: 0.10511363636363637
tensor(3.0856)
tensor(19.6392)
[TRAIN] Epoch 17/20, Batch 23/34, Loss: 20.62681770324707, Acc: 0.10326086956521739
tensor(3.2296)
tensor(16.4043)
[TRAIN] Epoch 17/20, Batch 24/34, Loss: 20.585447311401367, Acc: 0.1015625
tensor(3.2368)
tensor(12.6458)
[TRAIN] Epoch 17/20, Batch 25/34, Loss: 20.397335052490234, Acc: 0.0975
tensor(3.1823)
tensor(20.6176)
[TRAIN] Epoch 17/20, Batch 26/34, Loss: 20.52820587158203, Acc: 0.0985576923076923
tensor(3.2787)
tensor(15.7459)
[TRAIN] Epoch 17/20, Batch 27/34, Loss: 20.47251319885254, Acc: 0.10185185185185185
tensor(3.1676)
tensor(15.0231)
[TRAIN] Epoch 17/20, Batch 28/34, Loss: 20.391021728515625, Acc: 0.10714285714285714
tensor(3.3007)
tensor(13.1718)
[TRAIN] Epoch 17/20, Batch 29/34, Loss: 20.255901336669922, Acc: 0.11206896551724138
tensor(3.6733)
tensor(12.0492)
[TRAIN] Epoch 17/20, Batch 30/34, Loss: 20.10478973388672, Acc: 0.1125
tensor(3.2237)
tensor(14.4035)
[TRAIN] Epoch 17/20, Batch 31/34, Loss: 20.024864196777344, Acc: 0.11491935483870967
tensor(3.5160)
tensor(15.6956)
[TRAIN] Epoch 17/20, Batch 32/34, Loss: 19.999448776245117, Acc: 0.115234375
tensor(3.4573)
tensor(15.4111)
[TRAIN] Epoch 17/20, Batch 33/34, Loss: 19.96517562866211, Acc: 0.11742424242424243
tensor(3.4804)
tensor(13.9542)
[TRAIN] Epoch 17/20, Batch 34/34, Loss: 19.474109649658203, Acc: 0.11580882352941177
tensor(3.0284)
tensor(17.0980)
[TRAIN] Epoch 18/20, Batch 1/34, Loss: 20.126415252685547, Acc: 0.0625
tensor(3.2601)
tensor(16.7262)
[TRAIN] Epoch 18/20, Batch 2/34, Loss: 20.056324005126953, Acc: 0.09375
tensor(3.3434)
tensor(16.5367)
[TRAIN] Epoch 18/20, Batch 3/34, Loss: 19.99755859375, Acc: 0.08333333333333333
tensor(3.5636)
tensor(14.7156)
[TRAIN] Epoch 18/20, Batch 4/34, Loss: 19.567974090576172, Acc: 0.09375
tensor(3.7562)
tensor(13.1054)
[TRAIN] Epoch 18/20, Batch 5/34, Loss: 19.02668571472168, Acc: 0.0875
tensor(3.7198)
tensor(16.0969)
[TRAIN] Epoch 18/20, Batch 6/34, Loss: 19.15834617614746, Acc: 0.07291666666666667
tensor(3.3999)
tensor(15.0279)
[TRAIN] Epoch 18/20, Batch 7/34, Loss: 19.053987503051758, Acc: 0.09821428571428571
tensor(3.0663)
tensor(15.8876)
[TRAIN] Epoch 18/20, Batch 8/34, Loss: 19.04147720336914, Acc: 0.109375
tensor(3.2469)
tensor(14.1028)
[TRAIN] Epoch 18/20, Batch 9/34, Loss: 18.85349464416504, Acc: 0.1111111111111111
tensor(4.1265)
tensor(13.9326)
[TRAIN] Epoch 18/20, Batch 10/34, Loss: 18.774059295654297, Acc: 0.10625
tensor(3.5734)
tensor(15.2472)
[TRAIN] Epoch 18/20, Batch 11/34, Loss: 18.778287887573242, Acc: 0.11363636363636363
tensor(3.4099)
tensor(17.0861)
[TRAIN] Epoch 18/20, Batch 12/34, Loss: 18.921430587768555, Acc: 0.11458333333333333
tensor(3.3051)
tensor(14.8962)
[TRAIN] Epoch 18/20, Batch 13/34, Loss: 18.866029739379883, Acc: 0.11057692307692307
tensor(3.3892)
tensor(15.0738)
[TRAIN] Epoch 18/20, Batch 14/34, Loss: 18.837244033813477, Acc: 0.12053571428571429
tensor(3.6187)
tensor(15.5565)
[TRAIN] Epoch 18/20, Batch 15/34, Loss: 18.859773635864258, Acc: 0.11666666666666667
tensor(3.0801)
tensor(16.1914)
[TRAIN] Epoch 18/20, Batch 16/34, Loss: 18.885507583618164, Acc: 0.1171875
tensor(3.0038)
tensor(15.9148)
[TRAIN] Epoch 18/20, Batch 17/34, Loss: 18.887453079223633, Acc: 0.11397058823529412
tensor(3.3025)
tensor(13.2342)
[TRAIN] Epoch 18/20, Batch 18/34, Loss: 18.756855010986328, Acc: 0.1111111111111111
tensor(3.5646)
tensor(15.7510)
[TRAIN] Epoch 18/20, Batch 19/34, Loss: 18.786266326904297, Acc: 0.10526315789473684
tensor(3.4844)
tensor(11.6356)
[TRAIN] Epoch 18/20, Batch 20/34, Loss: 18.60295295715332, Acc: 0.1
tensor(3.4669)
tensor(18.4294)
[TRAIN] Epoch 18/20, Batch 21/34, Loss: 18.759780883789062, Acc: 0.09523809523809523
tensor(3.3810)
tensor(19.0132)
[TRAIN] Epoch 18/20, Batch 22/34, Loss: 18.924978256225586, Acc: 0.09375
tensor(3.4108)
tensor(13.1285)
[TRAIN] Epoch 18/20, Batch 23/34, Loss: 18.821252822875977, Acc: 0.08967391304347826
tensor(3.5435)
tensor(15.5053)
[TRAIN] Epoch 18/20, Batch 24/34, Loss: 18.830734252929688, Acc: 0.08854166666666667
tensor(4.1517)
tensor(15.9314)
[TRAIN] Epoch 18/20, Batch 25/34, Loss: 18.880830764770508, Acc: 0.085
tensor(2.9936)
tensor(17.6890)
[TRAIN] Epoch 18/20, Batch 26/34, Loss: 18.950130462646484, Acc: 0.08653846153846154
tensor(3.7292)
tensor(13.3397)
[TRAIN] Epoch 18/20, Batch 27/34, Loss: 18.880455017089844, Acc: 0.09027777777777778
tensor(3.2515)
tensor(14.9709)
[TRAIN] Epoch 18/20, Batch 28/34, Loss: 18.856952667236328, Acc: 0.08928571428571429
tensor(3.8270)
tensor(15.2248)
[TRAIN] Epoch 18/20, Batch 29/34, Loss: 18.863670349121094, Acc: 0.09051724137931035
tensor(3.4609)
tensor(12.6025)
[TRAIN] Epoch 18/20, Batch 30/34, Loss: 18.770328521728516, Acc: 0.09375
tensor(2.8077)
tensor(11.7614)
[TRAIN] Epoch 18/20, Batch 31/34, Loss: 18.634803771972656, Acc: 0.09879032258064516
tensor(3.4386)
tensor(14.8717)
[TRAIN] Epoch 18/20, Batch 32/34, Loss: 18.624662399291992, Acc: 0.099609375
tensor(3.6532)
tensor(15.5008)
[TRAIN] Epoch 18/20, Batch 33/34, Loss: 18.640703201293945, Acc: 0.10227272727272728
tensor(3.1299)
tensor(13.5356)
[TRAIN] Epoch 18/20, Batch 34/34, Loss: 18.184350967407227, Acc: 0.10110294117647059
tensor(3.3647)
tensor(14.7631)
[TRAIN] Epoch 19/20, Batch 1/34, Loss: 18.127756118774414, Acc: 0.1875
tensor(3.3173)
tensor(12.2166)
[TRAIN] Epoch 19/20, Batch 2/34, Loss: 16.830839157104492, Acc: 0.125
tensor(3.6109)
tensor(14.2402)
[TRAIN] Epoch 19/20, Batch 3/34, Loss: 17.170948028564453, Acc: 0.10416666666666667
tensor(3.8088)
tensor(17.1443)
[TRAIN] Epoch 19/20, Batch 4/34, Loss: 18.116485595703125, Acc: 0.09375
tensor(3.4421)
tensor(15.6563)
[TRAIN] Epoch 19/20, Batch 5/34, Loss: 18.312862396240234, Acc: 0.125
tensor(3.9021)
tensor(14.6615)
[TRAIN] Epoch 19/20, Batch 6/34, Loss: 18.354665756225586, Acc: 0.125
tensor(3.8807)
tensor(14.8850)
[TRAIN] Epoch 19/20, Batch 7/34, Loss: 18.413379669189453, Acc: 0.125
tensor(4.0275)
tensor(15.4020)
[TRAIN] Epoch 19/20, Batch 8/34, Loss: 18.540401458740234, Acc: 0.125
tensor(3.4640)
tensor(14.6705)
[TRAIN] Epoch 19/20, Batch 9/34, Loss: 18.495296478271484, Acc: 0.1111111111111111
tensor(3.2217)
tensor(16.3939)
[TRAIN] Epoch 19/20, Batch 10/34, Loss: 18.607318878173828, Acc: 0.10625
tensor(3.8960)
tensor(16.3544)
[TRAIN] Epoch 19/20, Batch 11/34, Loss: 18.756696701049805, Acc: 0.11363636363636363
tensor(3.6965)
tensor(12.5873)
[TRAIN] Epoch 19/20, Batch 12/34, Loss: 18.550615310668945, Acc: 0.10416666666666667
tensor(3.0705)
tensor(14.1311)
[TRAIN] Epoch 19/20, Batch 13/34, Loss: 18.44684600830078, Acc: 0.11538461538461539
tensor(3.5220)
tensor(14.9556)
[TRAIN] Epoch 19/20, Batch 14/34, Loss: 18.449045181274414, Acc: 0.125
tensor(3.1571)
tensor(19.6109)
[TRAIN] Epoch 19/20, Batch 15/34, Loss: 18.736976623535156, Acc: 0.12083333333333333
tensor(3.3135)
tensor(13.0962)
[TRAIN] Epoch 19/20, Batch 16/34, Loss: 18.591520309448242, Acc: 0.11328125
tensor(3.4925)
tensor(14.7196)
[TRAIN] Epoch 19/20, Batch 17/34, Loss: 18.569196701049805, Acc: 0.125
tensor(3.0226)
tensor(14.1442)
[TRAIN] Epoch 19/20, Batch 18/34, Loss: 18.491283416748047, Acc: 0.125
tensor(3.3130)
tensor(13.1902)
[TRAIN] Epoch 19/20, Batch 19/34, Loss: 18.386648178100586, Acc: 0.13486842105263158
tensor(3.1211)
tensor(13.7442)
[TRAIN] Epoch 19/20, Batch 20/34, Loss: 18.31058120727539, Acc: 0.140625
tensor(3.4519)
tensor(11.0530)
[TRAIN] Epoch 19/20, Batch 21/34, Loss: 18.129358291625977, Acc: 0.13690476190476192
tensor(3.0756)
tensor(11.0448)
[TRAIN] Epoch 19/20, Batch 22/34, Loss: 17.947134017944336, Acc: 0.14772727272727273
tensor(3.9413)
tensor(17.8288)
[TRAIN] Epoch 19/20, Batch 23/34, Loss: 18.11334991455078, Acc: 0.14673913043478262
tensor(3.1769)
tensor(13.0761)
[TRAIN] Epoch 19/20, Batch 24/34, Loss: 18.035837173461914, Acc: 0.14583333333333334
tensor(3.0801)
tensor(13.6185)
[TRAIN] Epoch 19/20, Batch 25/34, Loss: 17.982349395751953, Acc: 0.1475
tensor(3.2203)
tensor(15.1686)
[TRAIN] Epoch 19/20, Batch 26/34, Loss: 17.997989654541016, Acc: 0.14423076923076922
tensor(3.4848)
tensor(13.9160)
[TRAIN] Epoch 19/20, Batch 27/34, Loss: 17.975872039794922, Acc: 0.1412037037037037
tensor(3.1705)
tensor(16.1442)
[TRAIN] Epoch 19/20, Batch 28/34, Loss: 18.02368927001953, Acc: 0.14508928571428573
tensor(3.3080)
tensor(14.4443)
[TRAIN] Epoch 19/20, Batch 29/34, Loss: 18.014331817626953, Acc: 0.1400862068965517
tensor(2.8183)
tensor(14.4861)
[TRAIN] Epoch 19/20, Batch 30/34, Loss: 17.99066734313965, Acc: 0.14166666666666666
tensor(3.3398)
tensor(11.7212)
[TRAIN] Epoch 19/20, Batch 31/34, Loss: 17.896162033081055, Acc: 0.14516129032258066
tensor(3.0420)
tensor(11.2462)
[TRAIN] Epoch 19/20, Batch 32/34, Loss: 17.783414840698242, Acc: 0.150390625
tensor(3.2864)
tensor(14.1864)
[TRAIN] Epoch 19/20, Batch 33/34, Loss: 17.774002075195312, Acc: 0.14772727272727273
tensor(2.7068)
tensor(8.7209)
[TRAIN] Epoch 19/20, Batch 34/34, Loss: 17.31425666809082, Acc: 0.14705882352941177
tensor(3.1492)
tensor(15.5048)
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from int64 to float64
  .format(dtypeobj_in, dtypeobj_out))
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: whoa-0-19.png is a low contrast image
  warn('%s is a low contrast image' % fname)
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/util/dtype.py:118: UserWarning: Possible sign loss when converting negative image of type int64 to positive image of type uint8.
  .format(dtypeobj_in, dtypeobj_out))
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/util/dtype.py:171: UserWarning: Downcasting int64 to uint8 without scaling because max value 255 fits in uint8
  "value {} fits in {}".format(a.dtype, dtype, a.max(), dtype))
tensor([ 142.5819,  129.5792,  142.0000,   33.8425,   21.8733])
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: whoa-1-19.png is a low contrast image
  warn('%s is a low contrast image' % fname)
tensor([ 137.4810,   68.6044,  142.0000,   27.6290,   14.7671])
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: whoa-2-19.png is a low contrast image
  warn('%s is a low contrast image' % fname)
tensor([ 127.7251,  156.5875,  142.0000,   26.9353,   16.5965])
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: whoa-3-19.png is a low contrast image
  warn('%s is a low contrast image' % fname)
tensor([  94.8196,   88.9132,  123.0000,   29.3256,   15.8575])
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: whoa-4-19.png is a low contrast image
  warn('%s is a low contrast image' % fname)
tensor([  73.7990,  160.0058,  123.0000,   34.0312,   19.2285])
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: whoa-5-19.png is a low contrast image
  warn('%s is a low contrast image' % fname)
tensor([ 103.3225,   84.9232,  123.0000,   25.9801,   12.8854])
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: whoa-6-19.png is a low contrast image
  warn('%s is a low contrast image' % fname)
tensor([ 110.7264,   51.1937,  142.0000,   24.6208,   17.3425])
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: whoa-7-19.png is a low contrast image
  warn('%s is a low contrast image' % fname)
tensor([  87.9768,   82.2383,  161.0000,   21.3411,   11.9310])
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: whoa-8-19.png is a low contrast image
  warn('%s is a low contrast image' % fname)
tensor([  89.6316,  173.4739,   37.0000,   31.9886,   19.6505])
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: whoa-9-19.png is a low contrast image
  warn('%s is a low contrast image' % fname)
tensor([ 130.3936,  117.1909,  142.0000,   32.7686,   20.5751])
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: whoa-10-19.png is a low contrast image
  warn('%s is a low contrast image' % fname)
tensor([  94.7895,   97.7500,  123.0000,   27.0200,   13.5931])
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: whoa-11-19.png is a low contrast image
  warn('%s is a low contrast image' % fname)
tensor([  71.9316,  129.5170,  123.0000,   34.7838,   18.0468])
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: whoa-12-19.png is a low contrast image
  warn('%s is a low contrast image' % fname)
tensor([  82.8632,  188.6733,   37.0000,   34.7079,   19.2855])
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: whoa-13-19.png is a low contrast image
  warn('%s is a low contrast image' % fname)
tensor([ 129.0773,  134.8139,  123.0000,   29.1272,   15.8714])
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: whoa-14-19.png is a low contrast image
  warn('%s is a low contrast image' % fname)
tensor([ 123.5493,   83.4880,  142.0000,   28.9339,   16.1385])
/home/shared/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: whoa-15-19.png is a low contrast image
  warn('%s is a low contrast image' % fname)
tensor([  90.7979,   96.2570,  123.0000,   24.6602,   12.4037])
[TRAIN] Epoch 20/20, Batch 1/34, Loss: 18.653976440429688, Acc: 0.125
tensor(3.5713)
tensor(16.4732)
tensor([  67.5392,   86.5553,  123.0000,   24.2575,   14.0705])
tensor([ 110.6898,  117.8273,  142.0000,   23.7247,   13.7514])
tensor([  94.3884,  103.4796,  123.0000,   26.6799,   15.2318])
tensor([  70.6541,   65.4114,  151.0000,   22.3272,   13.0139])
tensor([ 106.6446,  114.2451,  123.0000,   23.6771,   13.5074])
tensor([  72.9190,  120.1606,  123.0000,   28.5262,   14.7066])
tensor([ 108.7610,   61.3859,  123.0000,   26.7935,   14.2715])
tensor([  83.2204,  101.6013,  123.0000,   27.2192,   13.8765])
tensor([ 109.8440,   80.3190,  151.0000,   26.6432,   14.0457])
tensor([  54.5005,   93.4761,  123.0000,   26.2065,   14.3623])
tensor([  73.6931,  115.0453,  123.0000,   30.5739,   17.0060])
tensor([  34.3007,  115.8085,   37.0000,   26.8234,   16.1882])
tensor([ 120.1847,   66.8668,  123.0000,   24.0197,   12.3984])
tensor([  44.7971,   73.8108,  123.0000,   23.6735,   13.8340])
tensor([ 101.3031,   98.0741,  142.0000,   22.0749,   11.9668])
tensor([  49.6817,   48.4969,  151.0000,   17.7747,   11.5433])
[TRAIN] Epoch 20/20, Batch 2/34, Loss: 19.34921646118164, Acc: 0.0625
tensor(3.3906)
tensor(17.1591)
tensor([  57.8137,  116.4045,  123.0000,   24.7550,   13.0391])
tensor([ 106.2150,   66.3849,  151.0000,   26.0275,   14.6533])
tensor([  81.1019,   82.8784,  151.0000,   24.1390,   13.2879])
tensor([ 149.9856,   80.6432,  151.0000,   25.6996,   16.0274])
tensor([ 110.5433,   79.1436,  123.0000,   24.6458,   12.8567])
tensor([ 128.9306,  111.4146,  123.0000,   25.3230,   14.3008])
tensor([  88.5664,   87.5199,  151.0000,   22.6634,   12.5992])
tensor([ 105.3456,  122.3330,  123.0000,   25.4512,   13.7772])
tensor([  82.5608,   94.9778,  151.0000,   24.3737,   12.5853])
tensor([  83.0065,   92.7886,  123.0000,   25.2971,   12.9360])
tensor([  72.7846,   88.9990,  123.0000,   21.4473,   11.0354])
tensor([  87.6485,   94.4211,  151.0000,   23.8717,   12.5461])
tensor([ 113.2528,   91.9539,  123.0000,   30.5396,   15.8377])
tensor([  92.8297,   62.6356,  123.0000,   20.6911,   10.8682])
tensor([  90.4281,  108.5778,  151.0000,   28.0354,   14.8389])
tensor([  67.8167,  100.8895,  123.0000,   28.6397,   16.2216])
[TRAIN] Epoch 20/20, Batch 3/34, Loss: 19.74937629699707, Acc: 0.041666666666666664
tensor(3.4333)
tensor(15.8026)
tensor([ 153.2444,  137.4286,   37.0000,   22.9397,   15.8750])
tensor([ 134.2756,   86.8447,  151.0000,   25.0418,   14.0506])
tensor([ 100.9751,   77.3946,  151.0000,   24.1824,   13.1894])
tensor([  99.5053,   90.4166,  151.0000,   28.8513,   16.4500])
tensor([  66.4512,  102.3254,  151.0000,   25.8579,   14.9550])
tensor([ 136.9135,   74.7928,  151.0000,   25.0223,   14.1952])
tensor([ 178.9889,   90.5128,  151.0000,   27.7304,   17.0376])
tensor([  93.6993,   72.7456,  151.0000,   23.9158,   13.7035])
tensor([  76.8563,   88.2113,  151.0000,   25.2740,   14.9299])
tensor([  84.3615,   82.5157,  151.0000,   25.2040,   15.9750])
tensor([ 122.3896,   86.3777,  151.0000,   29.4152,   15.9829])
tensor([ 104.2287,   80.6313,  151.0000,   24.3985,   13.0025])
tensor([  59.0673,  114.5486,   37.0000,   26.6154,   14.4275])
tensor([  69.1613,   59.5659,  151.0000,   27.4024,   16.3154])
tensor([  98.1354,   74.2836,  151.0000,   27.9127,   15.9802])
tensor([ 176.0896,   88.7749,  123.0000,   27.1187,   16.8223])
[TRAIN] Epoch 20/20, Batch 4/34, Loss: 19.62100601196289, Acc: 0.046875
tensor(3.2701)
tensor(17.2279)
tensor([ 126.7060,  105.1062,  123.0000,   28.3798,   17.3589])
tensor([ 118.8365,   80.7779,  151.0000,   27.8622,   15.8935])
tensor([ 125.6363,   91.5375,  170.0000,   25.5589,   17.2823])
tensor([ 109.3596,   50.5151,  151.0000,   27.6356,   15.1565])
tensor([  92.1279,  118.8314,  151.0000,   21.1877,   13.5921])
tensor([ 134.1425,   94.3302,  151.0000,   23.4220,   13.3292])
tensor([ 159.9128,   94.2391,  151.0000,   29.0889,   16.0477])
tensor([ 107.5951,   93.0295,  151.0000,   27.7844,   15.8051])
tensor([  68.3484,   96.5679,  151.0000,   25.5309,   15.4332])
tensor([ 123.5805,   94.5318,  151.0000,   21.9111,   13.5081])
tensor([ 117.0536,  114.4079,  151.0000,   28.6961,   17.2894])
tensor([ 143.6245,  107.8017,  151.0000,   24.0949,   15.1593])
tensor([ 128.5626,  100.9033,   37.0000,   28.2229,   18.0866])
tensor([  94.2015,   99.8935,  151.0000,   24.6755,   14.2411])
tensor([ 108.4581,   69.3059,  151.0000,   27.6683,   16.2764])
tensor([  64.0281,  134.1563,   37.0000,   30.3959,   17.9073])
[TRAIN] Epoch 20/20, Batch 5/34, Loss: 19.796405792236328, Acc: 0.0625
tensor(3.5475)
tensor(15.5101)
tensor([  75.4448,   71.4414,  151.0000,   25.3231,   15.1274])
tensor([ 174.3440,   82.0899,   66.0000,   29.5633,   16.5133])
tensor([  88.4157,  111.4565,  151.0000,   29.8276,   17.9856])
tensor([  86.4514,  101.2746,  151.0000,   26.4170,   15.6911])
tensor([ 230.0966,   86.0290,  151.0000,   36.9435,   23.1130])
tensor([  98.6949,  103.3040,  151.0000,   27.5742,   16.8889])
tensor([  67.1303,   25.1016,  170.0000,   20.7927,   15.7350])
tensor([ 102.7231,  109.7067,  151.0000,   31.7866,   19.3243])
tensor([  79.8417,  131.1400,   37.0000,   31.4465,   20.4981])
tensor([  63.4499,  141.0478,   37.0000,   31.6888,   21.3990])
tensor([  87.4095,   96.3193,  151.0000,   34.5768,   21.3107])
tensor([  66.1801,  144.3787,   37.0000,   30.5917,   19.0284])
tensor([ 196.3426,  184.9844,   37.0000,   38.1961,   23.1902])
tensor([ 164.2648,   99.1582,  151.0000,   31.5504,   18.1630])
tensor([ 150.6705,  125.5364,  151.0000,   35.4409,   20.7875])
tensor([ 114.9451,  143.0118,  151.0000,   36.9056,   21.4946])
[TRAIN] Epoch 20/20, Batch 6/34, Loss: 19.673276901245117, Acc: 0.07291666666666667
tensor(3.8899)
tensor(17.7980)
tensor([ 202.2681,  165.1772,   37.0000,   31.7889,   22.0853])
tensor([ 192.7572,   99.1861,  151.0000,   38.6443,   21.9637])
tensor([ 111.8633,  160.6803,   37.0000,   36.4355,   24.4459])
tensor([ 142.1039,  104.0493,  151.0000,   40.8013,   23.5467])
tensor([  98.5107,  146.7836,   37.0000,   38.2281,   23.4406])
tensor([ 165.3134,   72.5411,   66.0000,   33.6403,   18.9996])
tensor([ 121.7302,   95.4170,  151.0000,   32.7428,   18.3206])
tensor([ 171.0491,  124.1430,    9.0000,   35.4448,   20.5469])
tensor([ 185.9955,  108.9951,  151.0000,   36.0305,   23.5437])
tensor([ 138.2016,  106.0915,  151.0000,   34.7787,   19.7134])
tensor([ 164.3337,  102.1105,  151.0000,   36.7388,   21.4482])
tensor([ 159.6154,  138.4561,   56.0000,   35.9521,   21.4553])
tensor([ 69.2462,  83.3206,  37.0000,  27.3427,  17.9701])
tensor([ 112.2535,  143.3654,   37.0000,   38.0294,   22.7939])
tensor([ 244.2383,  178.7703,    9.0000,   41.5585,   30.0208])
tensor([  78.2156,   72.3470,  151.0000,   27.8863,   17.6759])
[TRAIN] Epoch 20/20, Batch 7/34, Loss: 19.961088180541992, Acc: 0.07142857142857142
tensor(3.5527)
tensor(21.5048)
tensor([ 116.2316,  125.2367,  113.0000,   36.8340,   23.8699])
tensor([ 125.5196,  128.6882,  113.0000,   38.3579,   22.5279])
tensor([  85.5030,   53.8853,  113.0000,   24.8843,   16.1724])
tensor([ 190.2595,  139.5258,  113.0000,   39.8969,   23.7478])
tensor([ 111.0599,  164.5162,   56.0000,   42.3590,   25.3557])
tensor([ 113.0053,  130.4840,   56.0000,   32.5567,   20.1596])
tensor([ 162.7748,  190.3711,   56.0000,   43.0652,   27.5636])
tensor([ 160.6889,  149.5634,    0.0000,   33.7134,   21.6095])
tensor([ 191.5751,  162.8991,   56.0000,   39.0462,   24.0392])
tensor([ 188.0312,  128.3701,    9.0000,   31.9784,   23.0658])
tensor([ 244.2721,  136.5970,    9.0000,   37.9214,   26.1492])
tensor([ 148.8722,  124.3308,   85.0000,   36.6005,   20.2955])
tensor([  86.8821,  166.8615,   56.0000,   39.4165,   24.6693])
tensor([  89.4300,  166.2616,   56.0000,   37.4693,   23.0326])
tensor([ 158.9821,  195.9949,   37.0000,   43.6455,   27.7154])
tensor([ 133.3971,  191.0601,   56.0000,   40.1693,   26.0396])
[TRAIN] Epoch 20/20, Batch 8/34, Loss: 20.5981502532959, Acc: 0.0703125
tensor(3.0997)
tensor(13.3680)
tensor([ 185.4929,  137.9701,    0.0000,   34.1988,   20.0774])
tensor([ 230.5777,  134.9196,    0.0000,   34.9157,   21.5066])
tensor([ 150.1374,  133.9543,    0.0000,   33.0488,   19.1050])
tensor([ 153.2408,  137.8369,   56.0000,   37.9128,   24.2155])
tensor([ 173.8492,  125.5646,    0.0000,   38.2099,   21.1236])
tensor([  60.8662,  133.5312,    9.0000,   31.0334,   21.5384])
tensor([ 128.4509,  167.1450,   56.0000,   38.3351,   22.0039])
tensor([ 102.2815,  182.8572,   56.0000,   39.4569,   24.5128])
tensor([ 124.4756,  109.3935,  113.0000,   35.7511,   20.1013])
tensor([ 132.9208,  162.9536,   37.0000,   35.2370,   23.3143])
tensor([ 129.7851,  141.5131,    0.0000,   35.6774,   21.8399])
tensor([ 119.1702,  150.8849,   56.0000,   39.3267,   22.0125])
tensor([ 162.8038,  108.2566,    0.0000,   41.2263,   22.9329])
tensor([  35.5174,   84.4512,  113.0000,   26.3434,   17.3823])
tensor([ 136.1735,   94.6544,  113.0000,   33.5620,   18.8711])
tensor([ 126.2172,   87.9114,   18.0000,   30.0375,   17.8319])
[TRAIN] Epoch 20/20, Batch 9/34, Loss: 20.13920783996582, Acc: 0.09722222222222222
tensor(3.3512)
tensor(14.2443)
tensor([ 119.2095,  116.3093,    0.0000,   24.0765,   15.2363])
tensor([ 136.2584,  133.9517,    0.0000,   24.0289,   15.1753])
tensor([  83.7430,  113.0124,  113.0000,   28.9676,   16.2733])
tensor([ 117.4212,  113.6340,    0.0000,   21.9558,   13.2024])
tensor([ 152.1122,   93.9628,    0.0000,   37.1511,   19.6031])
tensor([  76.0381,   85.3396,  113.0000,   26.3771,   14.8007])
tensor([  47.3718,   33.4676,  113.0000,   18.7851,   11.2331])
tensor([  89.7019,  105.5031,    0.0000,   28.6626,   17.1540])
tensor([ 139.1803,  138.1205,    0.0000,   32.7712,   17.5542])
tensor([ 142.5905,   99.7114,    0.0000,   26.8287,   14.3554])
tensor([ 151.4262,   94.0832,    0.0000,   31.7076,   16.3978])
tensor([ 175.2194,  114.0572,    0.0000,   31.4618,   17.9481])
tensor([ 116.5814,  101.3300,  113.0000,   31.5336,   17.2997])
tensor([ 109.4926,  156.6851,    0.0000,   30.3898,   18.2397])
tensor([  93.7346,  144.0264,   56.0000,   32.5110,   19.5501])
tensor([ 128.7613,  120.4064,  113.0000,   33.8340,   17.6411])
[TRAIN] Epoch 20/20, Batch 10/34, Loss: 19.884836196899414, Acc: 0.1
tensor(3.0850)
tensor(16.9260)
tensor([ 104.4557,   84.2197,  113.0000,   28.2634,   13.9492])
tensor([  84.7006,   84.3224,  113.0000,   24.3355,   13.1397])
tensor([ 112.1163,  105.9051,    0.0000,   24.3194,   12.6230])
tensor([  81.8809,  128.1541,   56.0000,   28.6716,   14.6706])
tensor([  56.5297,   74.0174,  113.0000,   21.5051,   12.0249])
tensor([ 107.9514,  110.2724,  113.0000,   30.7726,   15.6249])
tensor([  88.9765,  125.1992,   56.0000,   27.5400,   13.6749])
tensor([  94.1693,  100.1955,  113.0000,   30.8037,   15.5673])
tensor([ 128.2314,  117.5322,    0.0000,   28.8483,   14.8905])
tensor([ 115.3537,  106.4306,    0.0000,   22.7325,   12.0904])
tensor([ 100.5513,  109.9046,  113.0000,   29.6498,   15.2062])
tensor([ 120.8654,   70.3101,    0.0000,   26.4913,   13.1026])
tensor([  89.3793,  101.4692,  161.0000,   23.4653,   15.2499])
tensor([ 51.7940,  56.9871,   0.0000,  19.1227,  12.0589])
tensor([ 119.1033,   94.2734,  113.0000,   28.3263,   13.3797])
tensor([  44.2349,  127.6753,   37.0000,   28.4883,   17.4049])
[TRAIN] Epoch 20/20, Batch 11/34, Loss: 19.896305084228516, Acc: 0.10795454545454546
tensor(3.1376)
tensor(20.5422)
tensor([ 130.8916,   89.3003,    0.0000,   26.9721,   12.7409])
tensor([  57.3614,   95.7249,  161.0000,   21.9984,   11.8382])
tensor([ 103.6606,   79.9413,   47.0000,   25.2944,   12.6150])
tensor([  85.7999,  127.6846,  113.0000,   28.3276,   14.2187])
tensor([  56.0808,   85.7703,  113.0000,   26.7836,   14.4443])
tensor([  70.7623,   88.8493,  113.0000,   28.0080,   14.9025])
tensor([  53.7056,   39.9259,  113.0000,   22.0476,   12.4872])
tensor([  60.4445,  121.1626,  113.0000,   26.6675,   13.8973])
tensor([  75.6119,   51.4934,  113.0000,   22.5030,   11.9191])
tensor([ 39.3778,  91.8891,  37.0000,  24.9663,  14.7158])
tensor([  76.3205,   59.0082,  113.0000,   21.4893,   10.5401])
tensor([ 117.1720,   97.5375,    0.0000,   27.3987,   13.8848])
tensor([  73.8418,   55.3419,  113.0000,   27.5952,   14.5127])
tensor([ 108.9083,   71.5659,    0.0000,   20.5437,   10.1474])
tensor([  86.7971,   87.9415,  113.0000,   23.5884,   11.4463])
tensor([ 108.7642,   34.7905,    0.0000,   23.1962,   12.4923])
[TRAIN] Epoch 20/20, Batch 12/34, Loss: 20.211593627929688, Acc: 0.09895833333333333
tensor(3.3261)
tensor(16.1455)
tensor([ 100.0479,   67.1908,   47.0000,   24.5214,   11.4629])
tensor([ 106.9210,   52.8401,   47.0000,   24.9628,   11.8267])
tensor([ 100.9294,   73.6076,   47.0000,   26.1856,   12.1068])
tensor([  82.5104,   57.8198,  113.0000,   28.1720,   14.0866])
tensor([  76.7843,   68.8868,  113.0000,   26.5229,   13.9682])
tensor([  87.1961,  115.0921,  113.0000,   30.0370,   13.9930])
tensor([  74.5310,   90.5728,  113.0000,   28.8427,   15.1431])
tensor([  62.4671,   41.3715,  113.0000,   23.4399,   12.2400])
tensor([ 73.4685,  51.0786,  47.0000,  25.3913,  13.0868])
tensor([  88.1305,   78.1466,  113.0000,   31.7951,   16.7212])
tensor([  75.8626,   79.0391,  113.0000,   27.1464,   13.8861])
tensor([  46.9461,   71.7072,  113.0000,   21.4607,   11.3324])
tensor([ 107.3534,  100.8925,    0.0000,   23.0528,   11.3257])
tensor([  81.1370,   63.8323,  113.0000,   27.2318,   13.7967])
tensor([  58.1561,   73.1918,  113.0000,   25.2608,   13.8852])
tensor([  98.5733,   79.3248,  113.0000,   26.5478,   12.6297])
[TRAIN] Epoch 20/20, Batch 13/34, Loss: 20.154672622680664, Acc: 0.09615384615384616
tensor(3.9156)
tensor(20.2950)
tensor([ 122.9222,   60.3028,   28.0000,   23.0174,   11.8116])
tensor([  87.3238,   79.6643,  113.0000,   29.8776,   14.9922])
tensor([  64.6851,  120.1362,  113.0000,   33.0797,   16.9253])
tensor([  81.6396,  104.4992,   28.0000,   18.7379,   10.9135])
tensor([  62.3148,   92.5743,  113.0000,   27.2930,   14.1542])
tensor([  92.8901,  102.1377,  113.0000,   28.9850,   13.8718])
tensor([ 102.2394,  104.1539,    0.0000,   26.2008,   12.4154])
tensor([ 87.4472,  39.6735,  28.0000,  22.1675,  13.4042])
tensor([  74.3219,  108.6790,   28.0000,   28.4196,   13.6232])
tensor([ 121.0770,  107.4824,   47.0000,   31.7460,   15.6551])
tensor([ 147.1430,  117.5446,   28.0000,   32.1913,   21.1195])
tensor([ 100.2382,   88.8873,   28.0000,   21.3669,   10.6774])
tensor([ 100.2431,  107.1405,  113.0000,   30.8450,   15.4518])
tensor([  39.4385,  114.4262,   37.0000,   28.5522,   14.6894])
tensor([ 110.3488,   76.8140,   47.0000,   34.7909,   16.8156])
tensor([ 107.4992,   45.2788,   28.0000,   26.9171,   16.0965])
[TRAIN] Epoch 20/20, Batch 14/34, Loss: 20.444381713867188, Acc: 0.08928571428571429
tensor(3.6430)
tensor(17.4618)
tensor([ 125.4580,  150.2522,   28.0000,   38.2122,   19.5881])
tensor([ 121.4407,  129.7914,   28.0000,   32.3968,   16.5794])
tensor([ 123.2009,   74.4543,  170.0000,   30.0159,   14.7125])
tensor([ 117.4114,   98.3163,   94.0000,   33.7202,   15.5348])
tensor([  76.5240,  132.7437,   28.0000,   36.0744,   18.0819])
tensor([ 97.0709,  80.4012,  47.0000,  31.2567,  17.5180])
tensor([  70.2215,  111.5035,  113.0000,   31.9197,   17.2576])
tensor([  65.1293,   86.8280,  113.0000,   29.3760,   16.4233])
tensor([  81.5650,  102.8198,  113.0000,   35.6572,   18.2625])
tensor([  77.6590,   97.3423,  113.0000,   30.3490,   16.2490])
tensor([  75.4935,   85.9403,  113.0000,   32.1160,   17.0765])
tensor([ 101.9988,  139.1587,   28.0000,   43.6189,   20.7480])
tensor([ 107.5837,  127.5012,   28.0000,   40.2477,   23.0055])
tensor([  97.6009,  133.2085,   28.0000,   39.0503,   18.7797])
tensor([ 104.8614,  106.7902,   47.0000,   31.9872,   16.0363])
tensor([  27.9990,   72.8409,  142.0000,   25.8155,   18.5535])
[TRAIN] Epoch 20/20, Batch 15/34, Loss: 20.48841094970703, Acc: 0.0875
tensor(3.7369)
tensor(13.8759)
tensor([ 157.3235,  122.8247,   28.0000,   33.2832,   20.5246])
tensor([  93.6692,  131.0842,   94.0000,   40.5310,   23.6688])
tensor([ 124.3169,  119.9795,   47.0000,   37.2176,   18.0704])
tensor([ 73.7359,  86.8910,  47.0000,  30.4383,  16.8094])
tensor([  91.2551,  157.5076,   28.0000,   38.0736,   19.8787])
tensor([  83.3346,  145.8901,   47.0000,   40.4395,   21.4973])
tensor([ 114.0040,   84.1434,   47.0000,   36.0886,   18.1656])
tensor([  71.6909,  131.0151,   28.0000,   36.4755,   19.4489])
tensor([ 104.5220,   49.2361,   47.0000,   28.9885,   17.6036])
tensor([ 110.5361,  137.8615,   28.0000,   43.4388,   22.1395])
tensor([ 151.0344,   81.7121,   47.0000,   40.2026,   20.9747])
tensor([  77.2664,  139.3945,   28.0000,   41.3092,   21.5303])
tensor([ 77.7551,  89.5196,  47.0000,  28.7841,  16.1236])
tensor([  68.8448,  183.0618,   47.0000,   39.1094,   21.3122])
tensor([ 194.2329,  161.4990,   28.0000,   46.6385,   27.5772])
tensor([ 154.4857,  114.6301,   47.0000,   43.0277,   22.9238])
[TRAIN] Epoch 20/20, Batch 16/34, Loss: 20.308687210083008, Acc: 0.09765625
tensor(4.5075)
tensor(15.6131)
tensor([  85.6240,  162.6281,   37.0000,   45.4439,   24.9664])
tensor([ 130.5693,  149.5150,   94.0000,   45.6097,   24.4956])
tensor([  82.2506,  165.1006,   94.0000,   45.1943,   24.9324])
tensor([ 103.8868,  170.5245,   28.0000,   45.0810,   23.9799])
tensor([ 155.7570,  155.7745,   47.0000,   48.3536,   25.3154])
tensor([ 182.7941,  123.1558,  170.0000,   42.8768,   26.4796])
tensor([ 174.9708,  124.9543,   47.0000,   39.3535,   20.3541])
tensor([ 104.0500,   54.0978,  170.0000,   29.7438,   18.0769])
tensor([ 116.1976,  132.2489,   47.0000,   40.6235,   22.4396])
tensor([ 126.9416,  120.7428,   94.0000,   43.5451,   22.5003])
tensor([ 116.2162,   81.8902,  170.0000,   40.9071,   22.2002])
tensor([  64.8604,  159.9217,   37.0000,   44.2074,   24.5599])
tensor([ 113.6932,  189.8308,   28.0000,   32.1948,   25.0958])
tensor([ 155.5144,  152.2980,  170.0000,   45.9326,   24.5119])
tensor([  90.0046,  164.0374,   37.0000,   43.8345,   24.0364])
tensor([ 173.1842,  110.4779,  170.0000,   35.2660,   21.3047])
[TRAIN] Epoch 20/20, Batch 17/34, Loss: 20.29762077331543, Acc: 0.11029411764705882
tensor(3.4585)
tensor(16.5297)
tensor([ 128.1096,  152.8557,   28.0000,   36.0500,   22.5927])
tensor([ 108.0545,   82.8811,   47.0000,   36.3947,   18.7661])
tensor([ 140.7296,  133.4185,   94.0000,   49.7344,   25.8443])
tensor([ 127.0982,  111.3795,   47.0000,   40.3938,   21.2810])
tensor([ 121.4498,  125.3539,   47.0000,   44.1340,   23.3786])
tensor([  92.1717,  108.0277,   37.0000,   39.9019,   21.2131])
tensor([ 145.1736,  113.7260,   47.0000,   42.3813,   22.8750])
tensor([  74.4325,  123.0735,   47.0000,   36.1178,   19.9529])
tensor([ 169.4348,  177.1015,   47.0000,   50.9709,   26.4133])
tensor([ 133.8347,  168.4637,   28.0000,   43.4213,   21.8714])
tensor([ 162.6294,  148.5163,   47.0000,   47.1241,   24.8992])
tensor([  71.8729,  130.5639,   37.0000,   38.4551,   21.3792])
tensor([  95.2392,  177.8096,   37.0000,   48.9852,   25.6862])
tensor([ 156.5621,   81.9855,   47.0000,   38.5163,   19.2437])
tensor([ 98.1064,  65.9520,  47.0000,  45.6868,  25.9687])
tensor([ 156.9526,  171.7374,   47.0000,   47.6974,   24.9660])
[TRAIN] Epoch 20/20, Batch 18/34, Loss: 20.28042984008789, Acc: 0.1076388888888889
tensor(3.3421)
tensor(15.7295)
tensor([ 63.7944,  83.3450,  47.0000,  30.2403,  17.3536])
tensor([  68.9213,  160.9090,   37.0000,   42.5556,   22.8994])
tensor([ 130.6389,  126.4403,   47.0000,   41.6053,   20.6387])
tensor([ 134.7602,  143.5539,   47.0000,   44.1436,   22.9759])
tensor([ 120.9108,  107.2867,   47.0000,   38.2002,   19.5658])
tensor([ 117.9292,  128.0663,   94.0000,   43.0566,   22.5562])
tensor([  77.2695,  111.9393,   94.0000,   34.9360,   18.8837])
tensor([ 131.6465,   98.9262,  180.0000,   39.8532,   20.9700])
tensor([  58.8519,  120.2217,   37.0000,   33.2653,   17.9738])
tensor([ 147.9143,   63.3911,   47.0000,   32.2351,   18.3447])
tensor([  92.0926,  121.0395,   94.0000,   35.9680,   19.5079])
tensor([ 155.9751,  158.4448,   47.0000,   38.5758,   21.0083])
tensor([ 86.9424,  79.4296,  47.0000,  38.3492,  21.5503])
tensor([ 149.4020,  118.1417,   47.0000,   38.2199,   20.9277])
tensor([ 149.4495,   92.2112,   47.0000,   38.4236,   19.3064])
tensor([ 125.0491,  120.5915,  132.0000,   34.1320,   17.9694])
[TRAIN] Epoch 20/20, Batch 19/34, Loss: 20.21680450439453, Acc: 0.10855263157894737
tensor(2.9313)
tensor(14.3546)
tensor([ 109.7583,   96.5939,  132.0000,   32.3006,   16.8337])
tensor([ 67.7674,  80.9106,  18.0000,  28.2723,  17.1351])
tensor([ 138.5942,  119.0382,    9.0000,   37.1562,   20.2002])
tensor([  72.8774,  131.6010,   47.0000,   31.3063,   17.5867])
tensor([  77.1542,  116.8051,   18.0000,   35.5274,   19.4569])
tensor([ 65.0148,  96.6631,  18.0000,  29.6954,  16.0962])
tensor([ 110.2532,  116.6796,  132.0000,   34.4666,   17.9931])
tensor([ 145.4352,  108.8126,   47.0000,   35.4513,   18.9125])
tensor([ 102.0213,   93.2010,    9.0000,   29.6060,   15.9229])
tensor([  69.0276,  122.2165,   47.0000,   33.7883,   19.1452])
tensor([  98.3805,  118.5241,   18.0000,   36.0031,   19.4879])
tensor([ 56.6431,  90.8099,  18.0000,  27.0543,  15.7137])
tensor([ 92.2699,  92.9379,  18.0000,  34.6929,  20.0890])
tensor([ 113.2646,   79.6831,   47.0000,   33.0305,   17.3240])
tensor([ 135.3224,  146.8161,   47.0000,   39.4616,   21.0027])
tensor([ 131.8003,   84.6864,   47.0000,   37.6898,   20.2859])
[TRAIN] Epoch 20/20, Batch 20/34, Loss: 20.070261001586914, Acc: 0.10625
tensor(3.4050)
tensor(16.6255)
tensor([ 135.7272,  112.9272,  132.0000,   32.1112,   16.6251])
tensor([  96.6268,   61.9048,  104.0000,   29.3731,   14.9791])
tensor([ 143.8611,  122.3762,   47.0000,   31.9793,   16.9079])
tensor([ 47.3306,  88.2791,   9.0000,  30.5589,  16.4208])
tensor([  72.5084,   81.9867,  104.0000,   29.5009,   15.9043])
tensor([ 117.1648,  123.5485,    9.0000,   34.6966,   18.1568])
tensor([ 66.0867,  86.3589,  18.0000,  28.8287,  15.5977])
tensor([  74.8867,  151.3512,    9.0000,   43.7845,   22.8084])
tensor([  76.7506,   78.7584,  104.0000,   27.9552,   14.7860])
tensor([ 100.8024,  110.5255,   18.0000,   30.8395,   18.0642])
tensor([ 136.8666,   84.7997,   47.0000,   32.7803,   17.3059])
tensor([ 124.7869,  130.1210,    9.0000,   33.9581,   17.7453])
tensor([  55.8873,  108.1413,   37.0000,   34.5629,   18.1601])
tensor([ 88.9715,  93.7232,  18.0000,  31.6377,  16.6044])
tensor([ 65.9952,  90.4664,  18.0000,  28.9670,  15.3634])
tensor([ 130.4528,  115.0923,   18.0000,   36.5255,   18.0664])
[TRAIN] Epoch 20/20, Batch 21/34, Loss: 20.068368911743164, Acc: 0.10714285714285714
tensor(3.0961)
tensor(16.9135)
tensor([  64.5207,   51.8061,  104.0000,   28.4316,   15.4596])
tensor([ 106.6852,   71.9310,   18.0000,   30.2257,   16.9227])
tensor([ 114.3002,   96.5568,    9.0000,   30.6015,   16.0836])
tensor([ 134.6075,   89.4344,    9.0000,   29.9065,   16.0748])
tensor([ 110.3633,  114.4678,    0.0000,   27.6872,   15.4165])
tensor([ 106.3821,   98.4291,   18.0000,   33.3734,   19.8799])
tensor([  92.2641,   63.8819,  104.0000,   32.6321,   17.2142])
tensor([  84.2005,   69.4858,  104.0000,   33.5429,   18.3452])
tensor([  77.3700,  107.7579,   18.0000,   33.0222,   18.5757])
tensor([  84.8269,  114.8541,  132.0000,   26.5316,   14.4065])
tensor([ 107.4005,   55.3783,   18.0000,   29.1130,   15.2863])
tensor([ 103.4220,  114.8020,  132.0000,   34.8558,   18.0779])
tensor([ 105.7926,   94.8960,   18.0000,   33.6096,   16.7145])
tensor([ 85.8666,  96.7859,  18.0000,  33.0750,  16.4629])
tensor([ 91.5001,  78.5534,  18.0000,  31.6801,  16.6340])
tensor([ 130.2043,  104.3181,    9.0000,   31.2350,   16.8933])
[TRAIN] Epoch 20/20, Batch 22/34, Loss: 20.06570053100586, Acc: 0.10795454545454546
tensor(3.3718)
tensor(14.6930)
tensor([ 128.6299,  131.2137,  132.0000,   34.8724,   18.4740])
tensor([  94.9125,  113.4113,   18.0000,   37.7941,   19.6027])
tensor([ 109.4771,   98.9384,   18.0000,   32.4515,   16.3806])
tensor([  92.9271,  122.2568,   18.0000,   37.7484,   19.5140])
tensor([ 40.7514,  88.8334,  18.0000,  30.2478,  17.2653])
tensor([ 56.7065,  87.4034,  18.0000,  28.1257,  14.5012])
tensor([  89.0340,  123.6336,   18.0000,   38.3035,   19.6442])
tensor([  52.3381,  122.1295,   18.0000,   37.9199,   19.7747])
tensor([ 138.2424,   79.0125,  132.0000,   26.8081,   14.2036])
tensor([  99.4013,  145.5365,   56.0000,   35.1988,   18.2372])
tensor([ 101.5406,   72.0648,  132.0000,   32.4671,   17.1454])
tensor([  95.7761,   79.5919,  104.0000,   28.1944,   14.7859])
tensor([ 72.0810,  82.0994,  18.0000,  31.9821,  18.2445])
tensor([  88.8717,  122.6358,   18.0000,   37.0751,   20.5523])
tensor([  84.8347,  104.1721,   18.0000,   37.0493,   19.7263])
tensor([ 110.4002,   95.6118,  104.0000,   36.4980,   17.9433])
[TRAIN] Epoch 20/20, Batch 23/34, Loss: 19.978702545166016, Acc: 0.10869565217391304
tensor(3.4278)
tensor(12.8990)
tensor([  78.2886,  114.7879,   18.0000,   35.0957,   17.3801])
tensor([ 140.5484,   82.5710,  132.0000,   35.1388,   18.7368])
tensor([ 152.7077,  108.1061,  132.0000,   36.8467,   19.6858])
tensor([  82.6372,   95.1847,  104.0000,   38.6094,   19.2894])
tensor([ 126.2390,   75.0837,  104.0000,   42.7647,   21.4364])
tensor([  92.5167,  100.2963,    9.0000,   38.6636,   20.8055])
tensor([ 104.8741,  111.7051,   85.0000,   39.8104,   19.5040])
tensor([ 173.1641,  151.7438,   85.0000,   52.3840,   26.6589])
tensor([  77.3167,   82.9768,  104.0000,   31.3670,   16.3382])
tensor([ 72.3110,  93.2131,  18.0000,  34.8067,  17.3030])
tensor([  63.4668,   84.5861,  104.0000,   32.2087,   16.9905])
tensor([  80.1584,  113.6617,    9.0000,   35.9555,   18.9998])
tensor([  87.3952,   60.7246,  104.0000,   27.4128,   13.6003])
tensor([  66.3508,  107.6786,  104.0000,   35.1978,   17.9510])
tensor([  97.5149,   85.0633,  132.0000,   33.3085,   16.9808])
tensor([  99.8267,   96.6260,  104.0000,   39.0044,   19.7571])
[TRAIN] Epoch 20/20, Batch 24/34, Loss: 19.826541900634766, Acc: 0.109375
tensor(3.2978)
tensor(14.7717)
tensor([ 141.7855,  110.0261,    9.0000,   42.0983,   22.0345])
tensor([  89.3972,   84.4680,  104.0000,   37.9381,   19.8277])
tensor([ 128.5883,   96.6118,  161.0000,   39.3087,   19.2452])
tensor([ 104.5649,   85.9605,  104.0000,   38.3111,   19.6721])
tensor([  73.9671,   95.6807,  104.0000,   34.6728,   17.3426])
tensor([  63.6386,  112.3165,  104.0000,   37.8255,   19.1786])
tensor([ 88.3124,  90.9652,  18.0000,  43.2237,  24.0757])
tensor([ 180.1182,  158.8767,    9.0000,   50.9769,   26.6724])
tensor([ 143.9798,  124.7130,   85.0000,   42.3671,   21.0696])
tensor([ 174.8245,  162.7726,   85.0000,   54.5239,   26.4193])
tensor([  46.8415,  109.2483,   18.0000,   36.6732,   19.2807])
tensor([ 102.5823,   56.3581,  142.0000,   39.9817,   20.6096])
tensor([ 104.3590,   84.7042,  142.0000,   34.2928,   17.5439])
tensor([  98.7742,   76.9046,  142.0000,   35.3200,   20.3360])
tensor([ 134.6200,  161.5206,   85.0000,   52.7573,   27.2812])
tensor([  95.8351,   54.2599,  142.0000,   30.1753,   15.2333])
[TRAIN] Epoch 20/20, Batch 25/34, Loss: 19.756258010864258, Acc: 0.1125
tensor(3.0448)
tensor(15.7319)
tensor([ 143.0585,  120.4453,  161.0000,   39.9949,   19.6789])
tensor([  74.4983,  132.0154,   56.0000,   43.6404,   20.8533])
tensor([  93.2811,   70.4730,  142.0000,   33.9731,   17.3900])
tensor([ 150.4663,  140.0649,   56.0000,   45.3891,   23.8309])
tensor([  83.8442,   71.2156,  142.0000,   36.9792,   20.8568])
tensor([ 132.1346,  141.2215,  161.0000,   44.3876,   21.4952])
tensor([  90.6356,  166.5959,   56.0000,   41.9749,   20.1822])
tensor([ 143.0169,  139.2888,   85.0000,   47.6034,   22.1788])
tensor([  98.6673,   78.4684,  142.0000,   40.5512,   21.7227])
tensor([  97.1762,  104.1106,  142.0000,   39.2233,   20.3193])
tensor([ 107.8810,  126.2885,   85.0000,   43.8578,   20.6186])
tensor([ 103.0788,  102.1979,   85.0000,   36.9847,   17.8618])
tensor([ 162.9871,  152.5533,  161.0000,   51.8123,   24.1604])
tensor([ 164.6355,  163.7180,   56.0000,   45.5957,   22.7487])
tensor([ 100.9717,  128.7605,   85.0000,   48.6030,   22.8454])
tensor([  86.8400,  109.8116,   85.0000,   39.0922,   18.8720])
[TRAIN] Epoch 20/20, Batch 26/34, Loss: 19.71858024597168, Acc: 0.11057692307692307
tensor(3.5958)
tensor(17.1116)
tensor([ 168.0185,   89.4510,  161.0000,   45.5981,   24.4140])
tensor([ 133.1390,  148.2762,   85.0000,   52.7481,   23.7961])
tensor([  68.8598,  106.2551,   56.0000,   37.0549,   18.8339])
tensor([  62.1173,  127.4638,   85.0000,   38.7287,   18.0276])
tensor([ 134.4554,  117.0918,  142.0000,   41.2981,   20.5830])
tensor([ 154.3303,   99.0804,  142.0000,   41.9101,   22.0676])
tensor([ 157.9858,  125.6354,    0.0000,   39.2036,   20.0637])
tensor([ 131.1730,  135.6569,   56.0000,   42.2771,   22.0451])
tensor([ 155.8721,  128.6546,  161.0000,   48.9042,   24.1712])
tensor([  93.2729,  108.0649,  142.0000,   39.7151,   19.0464])
tensor([ 147.7558,  138.3751,  161.0000,   47.8215,   21.6765])
tensor([ 119.7694,  108.4093,   75.0000,   33.4568,   16.7978])
tensor([  79.0775,  123.4767,  142.0000,   39.5769,   19.5966])
tensor([ 108.4966,   83.9006,  142.0000,   46.8910,   24.8195])
tensor([ 162.9097,   79.3071,  161.0000,   40.7225,   22.0759])
tensor([  90.1221,   90.7061,  161.0000,   35.9074,   17.3672])
[TRAIN] Epoch 20/20, Batch 27/34, Loss: 19.755203247070312, Acc: 0.1111111111111111
tensor(3.8591)
tensor(16.7750)
tensor([ 135.7328,  142.0591,  161.0000,   54.9654,   25.4752])
tensor([  97.6728,  111.2831,  161.0000,   40.2741,   18.9491])
tensor([ 130.4816,  140.0990,   75.0000,   41.5671,   21.4056])
tensor([  68.3477,   93.2742,  142.0000,   35.2827,   16.7377])
tensor([ 137.3129,  100.0215,   75.0000,   33.1930,   17.3189])
tensor([  80.1543,  114.5525,   56.0000,   36.9565,   18.9178])
tensor([  63.7587,  115.5528,   56.0000,   33.5537,   16.3105])
tensor([ 138.5427,  128.7920,  161.0000,   49.2951,   26.2056])
tensor([ 113.8025,  130.5812,   75.0000,   44.2553,   21.0761])
tensor([ 136.3137,  109.6009,   75.0000,   36.3400,   18.3959])
tensor([ 122.0039,  166.1626,   56.0000,   47.3637,   23.7053])
tensor([ 150.0265,   74.5919,  123.0000,   40.4269,   20.8867])
tensor([  73.9823,  119.7197,   75.0000,   38.3455,   19.3670])
tensor([ 171.8333,  146.6888,   75.0000,   52.3413,   26.1858])
tensor([ 170.8878,  194.5770,   75.0000,   54.7056,   26.2224])
tensor([ 149.9771,  159.6783,  161.0000,   48.4769,   23.5368])
[TRAIN] Epoch 20/20, Batch 28/34, Loss: 19.786590576171875, Acc: 0.11160714285714286
tensor(3.3881)
tensor(14.5378)
tensor([ 140.7445,  102.4518,   75.0000,   30.7615,   16.4456])
tensor([ 157.0013,   93.9590,   75.0000,   35.2082,   18.9313])
tensor([  64.5700,  110.7337,   75.0000,   33.0973,   15.6229])
tensor([ 162.0651,  141.7590,    0.0000,   39.5457,   21.4243])
tensor([  79.8081,  144.7634,   75.0000,   40.8798,   19.2633])
tensor([ 104.9127,  134.2461,   56.0000,   34.3636,   17.9164])
tensor([  92.4049,  136.0708,   85.0000,   40.4982,   19.3317])
tensor([ 131.7706,  120.5895,   75.0000,   43.0857,   19.7682])
tensor([  81.1694,  129.5646,   75.0000,   41.9062,   20.0077])
tensor([ 101.5910,  114.0671,   75.0000,   40.0599,   18.5418])
tensor([ 120.7387,  119.0819,  161.0000,   39.5834,   19.3903])
tensor([ 101.1887,  126.7955,  161.0000,   40.2397,   20.0359])
tensor([ 130.3450,   97.6286,   75.0000,   44.1481,   22.1098])
tensor([  96.0288,  121.4441,   75.0000,   41.2586,   20.0747])
tensor([ 118.1544,  124.1419,   75.0000,   48.5436,   22.9197])
tensor([ 106.1897,   85.4344,   75.0000,   35.2859,   17.3149])
[TRAIN] Epoch 20/20, Batch 29/34, Loss: 19.722429275512695, Acc: 0.11637931034482758
tensor(3.5005)
tensor(17.4050)
tensor([ 102.5360,  141.2283,   56.0000,   33.8819,   17.9292])
tensor([ 78.0761,  99.4505,  75.0000,  34.2939,  18.0395])
tensor([  71.8977,  113.4690,   75.0000,   40.4251,   20.8985])
tensor([ 108.7106,   57.9454,   75.0000,   26.4853,   14.8658])
tensor([  83.3873,  116.9176,   75.0000,   31.5303,   16.3742])
tensor([ 159.6473,  149.4850,   75.0000,   43.5802,   22.7789])
tensor([  98.7143,   84.1586,  142.0000,   30.8250,   16.0929])
tensor([ 127.5520,  132.8575,  161.0000,   41.6577,   24.1424])
tensor([  80.3569,  109.1867,   75.0000,   38.0011,   19.5147])
tensor([  77.2788,   60.7225,  142.0000,   34.4436,   18.6046])
tensor([ 109.0624,  116.1426,   75.0000,   39.3256,   18.6058])
tensor([ 109.0666,   88.1901,   75.0000,   32.7568,   17.1907])
tensor([  86.1868,  135.4629,   75.0000,   36.7310,   18.4970])
tensor([ 124.0056,   89.2779,   75.0000,   29.5762,   16.2094])
tensor([  51.0362,  117.4083,   75.0000,   32.3364,   15.4315])
tensor([ 125.6074,  105.3524,   75.0000,   31.2171,   16.4317])
[TRAIN] Epoch 20/20, Batch 30/34, Loss: 19.761865615844727, Acc: 0.1125
tensor(3.3322)
tensor(13.8566)
tensor([  96.6973,   92.1668,  161.0000,   35.6182,   21.2046])
tensor([ 127.9264,  129.5132,   75.0000,   33.8188,   19.6326])
tensor([ 67.0666,  56.2644,  75.0000,  22.3466,  12.1793])
tensor([  75.5694,  132.9935,   75.0000,   39.3363,   19.7368])
tensor([  60.5304,  108.5429,   75.0000,   31.8329,   16.3473])
tensor([ 123.7815,  130.5632,  104.0000,   44.6785,   23.6676])
tensor([  75.0546,  113.2341,  161.0000,   32.2278,   16.5879])
tensor([ 153.5639,  145.4320,   75.0000,   39.9597,   22.6784])
tensor([ 120.1482,   70.1467,   75.0000,   26.7515,   15.4018])
tensor([  59.2082,  107.0515,   75.0000,   30.1062,   15.7211])
tensor([ 63.2400,  95.4726,  75.0000,  29.0856,  15.1429])
tensor([ 129.8360,   87.1978,   75.0000,   30.2321,   17.7639])
tensor([  83.5611,  160.5239,   75.0000,   40.4190,   21.0982])
tensor([  41.8938,   75.4623,  161.0000,   24.6059,   14.3399])
tensor([  64.5832,  107.2039,   75.0000,   29.5654,   16.3619])
tensor([  64.6703,  106.3866,   75.0000,   34.8754,   19.3979])
[TRAIN] Epoch 20/20, Batch 31/34, Loss: 19.678865432739258, Acc: 0.11088709677419355
tensor(3.2921)
tensor(17.3189)
tensor([ 119.8805,  103.8546,    0.0000,   28.4904,   17.5723])
tensor([  92.9197,   65.0944,  123.0000,   23.7374,   14.9342])
tensor([ 141.9115,  104.9958,  123.0000,   34.5985,   20.3540])
tensor([  66.6818,   87.2828,  161.0000,   29.1338,   17.3271])
tensor([  80.8681,   82.9821,  161.0000,   27.8455,   15.6146])
tensor([  52.3863,   54.8116,  104.0000,   24.7686,   15.5553])
tensor([  66.9434,   60.9238,  142.0000,   29.0777,   17.0442])
tensor([  87.6050,   86.6326,  123.0000,   28.9121,   15.8311])
tensor([ 130.3558,   87.9789,    0.0000,   27.1028,   18.7312])
tensor([  74.6653,   85.1131,  104.0000,   26.6226,   15.4951])
tensor([ 103.0135,  140.0088,  161.0000,   37.6193,   20.6389])
tensor([  81.0873,   55.2791,  161.0000,   25.0488,   16.3693])
tensor([ 105.9453,  128.5257,   75.0000,   32.1516,   20.5180])
tensor([  60.2913,   52.0868,  142.0000,   26.2805,   16.4991])
tensor([ 104.5410,  120.8975,  161.0000,   38.0967,   20.0482])
tensor([  83.1460,   92.1361,  161.0000,   30.1719,   17.0922])
[TRAIN] Epoch 20/20, Batch 32/34, Loss: 19.70799446105957, Acc: 0.109375
tensor(3.3865)
tensor(15.9137)
tensor([  96.1808,  150.1463,  180.0000,   38.7633,   22.2762])
tensor([ 138.7577,   95.5608,    0.0000,   28.2041,   19.5993])
tensor([ 92.0254,  98.0348,   0.0000,  26.4067,  17.0484])
tensor([  47.3054,   92.9434,  161.0000,   29.8481,   17.3695])
tensor([ 125.7470,   97.7938,    0.0000,   26.5202,   17.5725])
tensor([ 138.8095,  137.9659,    0.0000,   32.9649,   22.0278])
tensor([ 108.7069,  107.5048,  104.0000,   34.7675,   19.1470])
tensor([ 111.9104,   98.3049,  123.0000,   30.2549,   17.1102])
tensor([  87.0649,   98.4069,  161.0000,   30.5337,   18.0184])
tensor([  74.2977,  141.0134,   66.0000,   36.1301,   19.8557])
tensor([  81.2800,   49.0698,  123.0000,   24.6611,   16.0322])
tensor([ 105.6479,  112.3992,  123.0000,   33.2282,   19.3196])
tensor([  73.1519,   86.8197,  161.0000,   28.7068,   17.5077])
tensor([  79.5267,  102.5124,  180.0000,   30.5220,   19.2276])
tensor([  83.7769,   96.5135,  161.0000,   34.3224,   19.6313])
tensor([  77.7566,  104.0041,  180.0000,   29.1974,   16.2389])
[TRAIN] Epoch 20/20, Batch 33/34, Loss: 19.69563865661621, Acc: 0.10795454545454546
tensor(3.1928)
tensor(25.8897)
tensor([ 133.1359,  153.8808,  180.0000,   30.4037,   20.8381])
tensor([ 91.8481,  88.2956,   0.0000,  26.4957,  17.0561])
tensor([  73.1072,   80.2344,  161.0000,   26.4372,   17.1015])
[TRAIN] Epoch 20/20, Batch 34/34, Loss: 19.276737213134766, Acc: 0.10477941176470588
[VAL] Acc: 0.24858757062146894
[TEST] Acc: 0.3502824858757062
